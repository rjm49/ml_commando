{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 1.1 - Simple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import IPython\n",
    "import platform\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "print ('Python version:', platform.python_version())\n",
    "print ('IPython version:', IPython.__version__)\n",
    "print ('numpy version:', np.__version__)\n",
    "print ('scikit-learn version:', sklearn.__version__)\n",
    "print ('matplotlib version:', matplotlib.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "X_iris = iris.data\n",
    "y_iris = iris.target\n",
    "y_labels = iris.target_names\n",
    "\n",
    "print(\"Data shape={}, type={}, labels={}\\n\".format(X_iris.shape, type(X_iris), iris.feature_names))\n",
    "print(\"Target shape={}, type={}, labels={}\".format(y_iris.shape, type(y_iris), y_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_sepal = X_iris[:,2:4]\n",
    "# setosa_sepal =iris_sepal[y_iris == 0]\n",
    "\n",
    "X = iris_sepal[:,0].reshape(-1,1)\n",
    "y = iris_sepal[:,1]\n",
    "\n",
    "numpy.random.seed(666)\n",
    "test_split = 0.1\n",
    "test_n = int(test_split*len(X))\n",
    "test_indices = numpy.random.randint(0,len(X), size=test_n)\n",
    "train_indices = sorted(set(range(len(X))) - set(test_indices))\n",
    "\n",
    "X_train  = X[train_indices]\n",
    "y_train = y[train_indices]\n",
    "X_test = X[test_indices] \n",
    "y_test = y[test_indices]\n",
    "\n",
    "# convenience class to do the above...\n",
    "# from sklearn.cross_validation import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=666)\n",
    "\n",
    "plt.scatter(X_train, y_train)\n",
    "plt.scatter(X_test, y_test) #it's sneaky to look at your test data!\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_linear_regression(xs,ys, n_iter=1000):\n",
    "    N = len(xs)\n",
    "    m = 0.0\n",
    "    b = 0.0\n",
    "    learning_rate_alpha = 0.001\n",
    "\n",
    "    for i in range(n_iter):\n",
    "        cost = 0\n",
    "        y_hats = []\n",
    "        for x in xs:\n",
    "            y_hats.append( b + m*x )\n",
    "        \n",
    "        for x,y,y_hat in zip(xs,ys,y_hats):\n",
    "            cost += (y_hat- y)**2\n",
    "        if i % 100 == 0:\n",
    "            print(\"cost at iteration {} = {}\".format(i,cost))\n",
    "\n",
    "        del_m = 0.0\n",
    "        del_b = 0.0    \n",
    "        for x,y,y_hat in zip(xs,ys,y_hats):  \n",
    "            del_m += (1/N)*( 2*x * (y_hat - y) )\n",
    "            del_b += (1/N)*( 2   * (y_hat - y) )\n",
    "            \n",
    "        m = m - learning_rate_alpha * del_m\n",
    "        b = b - learning_rate_alpha * del_b\n",
    "    return y_hats, m, b, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "diy_y_hats, m, b, cost = my_linear_regression(X_train, y_train, n_iter=100)\n",
    "print(\"m=\",m,\"b=\",b)\n",
    "print(\"cost=\",cost)\n",
    "\n",
    "reg = SGDRegressor()\n",
    "\n",
    "reg.fit(X_train,y_train)\n",
    "y_hats = reg.predict(X_train)\n",
    "\n",
    "plt.scatter(X_train, y_train)\n",
    "plt.plot(X_train, diy_y_hats, color=\"green\", label=\"DIY\")\n",
    "plt.plot(X_train, y_hats, color=\"red\", label=\"sklearn\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "y_hats = reg.predict(X_train)\n",
    "\n",
    "print(\"RMSE is\", sqrt(metrics.mean_squared_error(y_train,y_hats)))\n",
    "\n",
    "R2_1 = reg.score(X_train,y_train)\n",
    "print(\"R2 from estimator is:\", R2_1)\n",
    "R2_2 = metrics.r2_score(y_train,y_hats)\n",
    "print(\"R2 from metrics is:\", R2_2)\n",
    "R2_3 = metrics.explained_variance_score(y_train,y_hats)\n",
    "print(\"Variance explained from metrics is:\", R2_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hats = reg.predict(X_test)\n",
    "\n",
    "print(\"RMSE is\", sqrt(metrics.mean_squared_error(y_test,y_hats)))\n",
    "R2_2 = metrics.r2_score(y_test,y_hats)\n",
    "print(\"R2 from metrics is:\", R2_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "- We loaded the Iris dataset and manually split it into training and test sets\n",
    "- We implemented linear regression using our own routine and using the sklearn library.\n",
    "- We checked the RMSE and R2 scores on both our training and test datasets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
