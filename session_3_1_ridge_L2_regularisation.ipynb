{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularisation (L2 or Ridge)\n",
    "## Cambridge ML Commando Course\n",
    "\n",
    "In this notebook we will:\n",
    "- create noisy data based on a pure signal\n",
    "- create regressors with various non-linear features\n",
    "- test their fits and plot them, along with printing their cross-validation scores\n",
    "- implement ridge regression to smooth out overfit, inspect how it works\n",
    "- plot a validation curve for our ridge regressor\n",
    "- plot learning curves for all our regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%pylab inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import sklearn\n",
    "import IPython\n",
    "import platform\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# from IPython.core.interactiveshell import InteractiveShell\n",
    "# InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "print ('Python version:', platform.python_version())\n",
    "print ('IPython version:', IPython.__version__)\n",
    "print ('numpy version:', np.__version__)\n",
    "print ('scikit-learn version:', sklearn.__version__)\n",
    "print ('matplotlib version:', matplotlib.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate noisy data\n",
    "Start by creating a \"truth\" function (here the sine function) and use it to generate some noisy samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pure = np.arange(0,2*3.1415,0.1)\n",
    "\n",
    "true_fun = lambda x : np.sin(x)\n",
    "\n",
    "np.random.seed(666)\n",
    "X = np.sort(random.choice(X_pure, size=30, replace=False))\n",
    "\n",
    "y_pure = np.sin(X_pure)\n",
    "# y = np.sin(X) + (np.random.random(len(X))-0.5)*1.0 # generate points with uniform noise\n",
    "y = true_fun(X) + np.random.randn(len(X))*0.25 # generate points with Gaussian noise\n",
    "plt.plot(X_pure, true_fun(X_pure))\n",
    "plt.scatter(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and train regressors\n",
    "Import the tools we need from sklearn.  We use PolynomialFeatures to create higher order and interaction features from our samples in X, which we scale as normal.\n",
    "\n",
    "We use Pipeline objects to organise these feature creation and scaling steps so that we don't need to apply each step explicitly.\n",
    "\n",
    "Here we create:\n",
    "- reg: standard linear regression\n",
    "- reg3: order-3 (cubic) polynomial regression\n",
    "- reg15: order-15 (quindecic) polynomial regression\n",
    "- ridge15: another quindecic polynomial regression but this time with L2 regularisation (you will need to uncomment the display code to see it)\n",
    "\n",
    "Note how:\n",
    "- The line _underfits_ the true curve\n",
    "- The cubic fits pretty well\n",
    "- The order-15 curve _overfits_ the true curve\n",
    "- The ridge-regression curve is a better fit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "X = X.reshape(-1,1)\n",
    "X_pure = X_pure.reshape(-1,1)\n",
    "\n",
    "plt.ylim(-1.6, 1.5)\n",
    "plt.plot(X_pure,true_fun(X_pure), linestyle=\"--\", label=\"true\")\n",
    "\n",
    "reg = LinearRegression()\n",
    "reg.fit(X,y)\n",
    "plt.scatter(X, y)\n",
    "plt.plot(X_pure, reg.predict(X_pure), label=\"linear\")\n",
    "\n",
    "scores = cross_val_score(reg, X, y, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "\n",
    "scaler3 = StandardScaler()\n",
    "poly3 = PolynomialFeatures(3)\n",
    "steps = [\n",
    "    (\"poly\",poly3),\n",
    "    (\"scale\",scaler3),\n",
    "    (\"reg\",LinearRegression())\n",
    "]\n",
    "reg3 = Pipeline(steps)\n",
    "\n",
    "reg3.fit(X, y)\n",
    "plt.plot(X_pure, reg3.predict(X_pure), label=\"cubic\")\n",
    "scores3 = cross_val_score(reg3, X, y, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "\n",
    "\n",
    "scaler15 = StandardScaler()\n",
    "poly15 = PolynomialFeatures(15)\n",
    "steps = [\n",
    "    (\"poly\",poly15),\n",
    "    (\"scale\",scaler15),\n",
    "    (\"reg\",LinearRegression())\n",
    "]\n",
    "reg15 = Pipeline( steps )\n",
    "\n",
    "reg15.fit(X,y)\n",
    "plt.plot(X_pure, reg15.predict(X_pure), label=\"quindecic (15)\")\n",
    "scores15 = cross_val_score(reg15, X, y, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "\n",
    "steps = [\n",
    "    (\"poly\",poly15),\n",
    "    (\"scale\",scaler15),\n",
    "    (\"reg\",Ridge(alpha=0.01))\n",
    "]\n",
    "ridge15 = Pipeline( steps )\n",
    "ridge15.fit(X,y)\n",
    "plt.plot(X_pure, ridge15.predict(X_pure), label=\"ridge (15)\")\n",
    "ridge_scores = cross_val_score(ridge15, X, y, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "print(\"Linear model\")\n",
    "print(-np.mean(scores), np.std(scores))\n",
    "\n",
    "print(\"Cubic model\")\n",
    "print(-np.mean(scores3), np.std(scores3))\n",
    "\n",
    "print(\"Quindecic model\")\n",
    "print(-np.mean(scores15), np.std(scores15))\n",
    "\n",
    "print(\"Ridge regression regularisation\")\n",
    "print(-np.mean(ridge_scores), np.std(ridge_scores))\n",
    "\n",
    "plt.gcf().set_size_inches(10,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Varying the regularisation weight\n",
    "In this section we vary the _alpha_ value (often styled $\\lambda$ in the literature) to see how this varies the smoothing of the curve.  We plot several values.\n",
    "\n",
    "Try out different values and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.logspace(-7, 3, 7)\n",
    "ax = plt.figure().gca()\n",
    "ax.scatter(X, y)\n",
    "for a in alphas:\n",
    "    steps = [\n",
    "    (\"poly\",poly15),\n",
    "    (\"scale\",scaler15),\n",
    "    (\"reg\",Ridge(alpha=a))\n",
    "    ]\n",
    "    new_ridge = Pipeline( steps )\n",
    "    new_ridge.fit(X,y)\n",
    "#     new_ridge_scores = cross_val_score(new_ridge, X, y, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "    ax.plot(X_pure, new_ridge.predict(X_pure), label=a)\n",
    "plt.ylim(-1.5,1.5)\n",
    "plt.legend(title=\"alpha\")\n",
    "plt.gcf().set_size_inches(10,8)\n",
    "plt.title('Ridge (15): Fit to datapoints under increasing regularisation')\n",
    "plt.axis('tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constraining the coefficients\n",
    "Ridge regression is just Linear Regression with L2 regularisation.  As we increase the regularisation hyperparameter (alpha), we cause the coefficients of the regression terms to shrink.\n",
    "\n",
    "Here we plot them for various values of alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_alphas = 20\n",
    "alphas =np.logspace(-4, 3, n_alphas)\n",
    "\n",
    "coefs = []\n",
    "powers = None\n",
    "scores = []\n",
    "for a in alphas:\n",
    "    steps = [\n",
    "    (\"poly\",poly15),\n",
    "    (\"scale\",scaler15),\n",
    "    (\"reg\",Ridge(alpha=a))\n",
    "    ]\n",
    "    new_ridge = Pipeline( steps )\n",
    "    new_ridge.fit(X,y)    \n",
    "    coefs.append(new_ridge.named_steps[\"reg\"].coef_)\n",
    "    score = numpy.mean(cross_val_score(new_ridge, X, y, scoring=\"neg_mean_squared_error\", cv=10))\n",
    "    scores.append(score)\n",
    "    if powers is None: # get these for use in labelling the series, so we can see what Poly features we have\n",
    "        powers = new_ridge.named_steps[\"poly\"].powers_\n",
    "\n",
    "coefs = numpy.array(coefs).T # puts the coefficients into a time-series per row\n",
    "# #############################################################################\n",
    "# Display results\n",
    "\n",
    "plt.gcf().set_size_inches(10,8)\n",
    "ax = plt.gca()\n",
    "\n",
    "ax.set_xscale('log')\n",
    "# ax.set_xlim(ax.get_xlim()[::-1])  # reverse axis\n",
    "ax.set_ylabel('Coefficient weight')\n",
    "axsc = ax.twinx()\n",
    "print(alphas.shape, len(coefs))\n",
    "\n",
    "for power,coef_vals in zip(powers, coefs):\n",
    "    ax.plot(alphas, coef_vals, label=\"$x^{}$\".format(\"{\"+str(int(power))+\"}\"))\n",
    "ax.legend()\n",
    "axsc.plot(alphas, scores, linestyle=\"--\", label=\"-ve MSE\")\n",
    "axsc.set_ylabel('-ve MSE score (higher=better!)')\n",
    "axsc.legend()\n",
    "    \n",
    "plt.xlabel('alpha')\n",
    "plt.title('Ridge coefficients as a function of the regularisation param')\n",
    "plt.axis('tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation curve\n",
    "Validation curves are useful tools for seeing which value is best of our regularisation hyperparameter.  Here we search through several value of alpha and plot how they affect performance on training and cross-validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "def plot_validation_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=None, param_name=\"C\", param_range = np.logspace(-3, 5, 10)):\n",
    "    \"\"\"\n",
    "    Generate a simple plot of the test and training learning curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "    cv : int, cross-validation generator or an iterable, optional\n",
    "        Determines the cross-validation splitting strategy.\n",
    "        Possible inputs for cv are:\n",
    "          - None, to use the default 3-fold cross-validation,\n",
    "          - integer, to specify the number of folds.\n",
    "          - :term:`CV splitter`,\n",
    "          - An iterable yielding (train, test) splits as arrays of indices.\n",
    "\n",
    "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
    "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
    "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
    "\n",
    "        Refer :ref:`User Guide <cross_validation>` for the various\n",
    "        cross-validators that can be used here.\n",
    "\n",
    "    n_jobs : int or None, optional (default=None)\n",
    "        Number of jobs to run in parallel.\n",
    "        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
    "        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
    "        for more details.\n",
    "\n",
    "    train_sizes : array-like, shape (n_ticks,), dtype float or int\n",
    "        Relative or absolute numbers of training examples that will be used to\n",
    "        generate the learning curve. If the dtype is float, it is regarded as a\n",
    "        fraction of the maximum size of the training set (that is determined\n",
    "        by the selected validation method), i.e. it has to be within (0, 1].\n",
    "        Otherwise it is interpreted as absolute sizes of the training sets.\n",
    "        Note that for classification the number of samples usually have to\n",
    "        be big enough to contain at least one sample from each class.\n",
    "        (default: np.linspace(0.1, 1.0, 5))\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    \n",
    "    train_scores, test_scores = validation_curve(\n",
    "    estimator, X, y, param_name=param_name, scoring=\"neg_mean_squared_error\", param_range=param_range,\n",
    "    cv=cv, n_jobs=n_jobs)\n",
    "\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "            \n",
    "    plt.grid()\n",
    "\n",
    "    plt.xlabel(param_name)\n",
    "    plt.ylabel(\"Score\")\n",
    "    lw = 2\n",
    "    plt.semilogx(param_range, train_scores_mean, label=\"Training score\",\n",
    "                 color=\"darkorange\", lw=lw)\n",
    "    plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.2,\n",
    "                     color=\"darkorange\", lw=lw)\n",
    "    plt.semilogx(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
    "                 color=\"navy\", lw=lw)\n",
    "    plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.2,\n",
    "                     color=\"navy\", lw=lw)\n",
    "\n",
    "    plt.gcf().set_size_inches(10,5)\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X15=scaler15.transform(poly15.transform(X)) # make a 15-degree polynomial version of X\n",
    "reg = Ridge() # this estimator is cloned for each value of alpha\n",
    "\n",
    "plot_validation_curve(reg, \"Ridge15\", X15, y, (-2,2), \n",
    "                      cv=10, \n",
    "#                       n_jobs=-1, \n",
    "                      param_name=\"alpha\", \n",
    "                      param_range=np.logspace(-10, 5, 30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning curves\n",
    "Learning curves are another useful tool, but they show how our estimator performs on training and cross-validation datasets as the size of the dataset increases.  This lets us know whether we need to get more data, add/remove features, regularise, or change our ML algorithm completely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \"\"\"\n",
    "    Generate a simple plot of the test and training learning curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "    cv : int, cross-validation generator or an iterable, optional\n",
    "        Determines the cross-validation splitting strategy.\n",
    "        Possible inputs for cv are:\n",
    "          - None, to use the default 3-fold cross-validation,\n",
    "          - integer, to specify the number of folds.\n",
    "          - :term:`CV splitter`,\n",
    "          - An iterable yielding (train, test) splits as arrays of indices.\n",
    "\n",
    "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
    "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
    "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
    "\n",
    "        Refer :ref:`User Guide <cross_validation>` for the various\n",
    "        cross-validators that can be used here.\n",
    "\n",
    "    n_jobs : int or None, optional (default=None)\n",
    "        Number of jobs to run in parallel.\n",
    "        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
    "        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
    "        for more details.\n",
    "\n",
    "    train_sizes : array-like, shape (n_ticks,), dtype float or int\n",
    "        Relative or absolute numbers of training examples that will be used to\n",
    "        generate the learning curve. If the dtype is float, it is regarded as a\n",
    "        fraction of the maximum size of the training set (that is determined\n",
    "        by the selected validation method), i.e. it has to be within (0, 1].\n",
    "        Otherwise it is interpreted as absolute sizes of the training sets.\n",
    "        Note that for classification the number of samples usually have to\n",
    "        be big enough to contain at least one sample from each class.\n",
    "        (default: np.linspace(0.1, 1.0, 5))\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, scoring=\"neg_mean_squared_error\", train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "#     print(test_scores_mean)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", alpha=0.5,\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", alpha=0.5,\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.gcf().set_size_inches(10,5)\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.25, random_state=0) # works better for small dataset\n",
    "\n",
    "train_sizes = np.linspace(0.1, 1.0, 20)\n",
    "print(train_sizes)\n",
    "plot_learning_curve(reg, \"Underfit (linear)\", X, y, (-2,0.5), cv=cv, n_jobs=4, train_sizes=train_sizes)\n",
    "plot_learning_curve(reg3, \"Good fit (cubic)\", X, y, (-2,0.5), cv=cv, n_jobs=4, train_sizes=train_sizes)\n",
    "plot_learning_curve(reg15, \"Overfit (15)\", X, y, (-.2e8,.25e7), cv=cv, n_jobs=4, train_sizes=train_sizes)\n",
    "plot_learning_curve(ridge15, \"Ridge (15)\", X, y, (-4,1), cv=cv, n_jobs=4, train_sizes=train_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "In this notebook we:\n",
    "- Created some noisy samples based on a true underlying function\n",
    "- Trained several regressors of increasing polynomial order\n",
    "- Checked for under- and over-fit (and good fit)\n",
    "- Trained a ridge regression model to mitigate overfit\n",
    "- Iterated over values of alpha to see how these affect regression curve complexity, and to see how coefficients shrink as alpha grows\n",
    "- Plotted a validation curve for alpha to look for the best value\n",
    "- Plotted learning curves of our iterators to look for tell-tale signs of good and bad fitting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
