{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M/L Commando Course, Cambridge 2018\n",
    "## Neural Networks\n",
    "\n",
    "We revisit our well-known Titanic data again, this time using Keras with Tensorflow to build Neural Network classifiers, for survival prediction (binary classification) and to estimate the class of a passenger (multiclass classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import exp\n",
    "from random import random, shuffle, choice, randint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras import Input\n",
    "from numpy import array, mean\n",
    "from pandas import concat\n",
    "from pandas import DataFrame\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Reshape\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    row.names pclass  survived                          name  age  \\\n",
      "12         13    1st         1  Aubert, Mrs Leontine Pauline  NaN   \n",
      "13         14    1st         1     Barkworth, Mr Algernon H.  NaN   \n",
      "\n",
      "       embarked      home.dest  room        ticket boat     sex  \n",
      "12    Cherbourg  Paris, France  B-35  17477 L69 6s    9  female  \n",
      "13  Southampton  Hessle, Yorks  A-23           NaN    B    male  \n"
     ]
    }
   ],
   "source": [
    "titanic_raw = pd.read_csv('data/titanic.csv')\n",
    "print (titanic_raw[12:14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       age  embarked=Cherbourg  embarked=Queenstown  embarked=Southampton  \\\n",
      "0  29.0000                 0.0                  0.0                   1.0   \n",
      "1   2.0000                 0.0                  0.0                   1.0   \n",
      "2  30.0000                 0.0                  0.0                   1.0   \n",
      "3  25.0000                 0.0                  0.0                   1.0   \n",
      "4   0.9167                 0.0                  0.0                   1.0   \n",
      "\n",
      "   pclass=1st  pclass=2nd  pclass=3rd  sex=female  sex=male  \n",
      "0         1.0         0.0         0.0         1.0       0.0  \n",
      "1         1.0         0.0         0.0         1.0       0.0  \n",
      "2         1.0         0.0         0.0         0.0       1.0  \n",
      "3         1.0         0.0         0.0         1.0       0.0  \n",
      "4         1.0         0.0         0.0         0.0       1.0  \n"
     ]
    }
   ],
   "source": [
    "from sklearn import feature_extraction\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def one_hot_dataframe(data, cols, replace=False):\n",
    "    dic_vecr = feature_extraction.DictVectorizer()\n",
    "    stuff_to_transform = data[cols]\n",
    "    dty_list = stuff_to_transform.to_dict(orient='records') #rjm49 - this call makes a dict for each record in the table, returns them all as a list\n",
    "    txd = dic_vecr.fit_transform(dty_list) #converts string types to 1-hot-encoded classes as a NumPy \"sparse array\"\n",
    "    vecData = pd.DataFrame( txd.toarray())\n",
    "    vecData.columns = dic_vecr.get_feature_names()\n",
    "    vecData.index = data.index\n",
    "    if replace is True: #replace the columns in data with those from our VecData object\n",
    "        data = data.drop(cols, axis=1)\n",
    "        data = data.join(vecData)\n",
    "    return (data, vecData)\n",
    "\n",
    "titanic, _ = one_hot_dataframe(titanic_raw, ['pclass', 'embarked', 'sex'], replace=True)\n",
    "titanic_target = titanic['survived']\n",
    "\n",
    "mean_age = titanic['age'].mean()\n",
    "titanic['age'].fillna(mean_age, inplace=True)\n",
    "\n",
    "titanic.fillna(0, inplace=True)\n",
    "\n",
    "titanic_data = titanic.drop(['name', 'row.names', 'survived', 'embarked', 'home.dest','ticket','boat','room'], axis=1) #can use inplace=True to alter original\n",
    "\n",
    "print(titanic_data.head())\n",
    "X_train, X_test, y_train, y_test = train_test_split(titanic_data, titanic_target, test_size=0.25, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_17 (Dense)             (None, 10)                100       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 11        \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 111\n",
      "Trainable params: 111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "984/984 [==============================] - 1s 841us/step - loss: 2.9079 - acc: 0.6687 - mean_squared_error: 0.3191\n",
      "Epoch 2/100\n",
      "984/984 [==============================] - 0s 108us/step - loss: 2.1534 - acc: 0.6687 - mean_squared_error: 0.3142\n",
      "Epoch 3/100\n",
      "984/984 [==============================] - 0s 95us/step - loss: 1.3713 - acc: 0.6728 - mean_squared_error: 0.2973\n",
      "Epoch 4/100\n",
      "984/984 [==============================] - 0s 96us/step - loss: 0.7303 - acc: 0.6829 - mean_squared_error: 0.2351\n",
      "Epoch 5/100\n",
      "984/984 [==============================] - 0s 99us/step - loss: 0.5888 - acc: 0.7226 - mean_squared_error: 0.1998\n",
      "Epoch 6/100\n",
      "984/984 [==============================] - 0s 104us/step - loss: 0.5680 - acc: 0.7246 - mean_squared_error: 0.1911\n",
      "Epoch 7/100\n",
      "984/984 [==============================] - 0s 107us/step - loss: 0.5518 - acc: 0.7480 - mean_squared_error: 0.1836\n",
      "Epoch 8/100\n",
      "984/984 [==============================] - 0s 95us/step - loss: 0.5367 - acc: 0.7652 - mean_squared_error: 0.1772\n",
      "Epoch 9/100\n",
      "984/984 [==============================] - 0s 130us/step - loss: 0.5235 - acc: 0.7754 - mean_squared_error: 0.1711\n",
      "Epoch 10/100\n",
      "984/984 [==============================] - 0s 114us/step - loss: 0.5118 - acc: 0.7774 - mean_squared_error: 0.1666\n",
      "Epoch 11/100\n",
      "984/984 [==============================] - 0s 103us/step - loss: 0.5025 - acc: 0.7967 - mean_squared_error: 0.1620\n",
      "Epoch 12/100\n",
      "984/984 [==============================] - 0s 94us/step - loss: 0.4914 - acc: 0.7978 - mean_squared_error: 0.1577\n",
      "Epoch 13/100\n",
      "984/984 [==============================] - 0s 116us/step - loss: 0.4862 - acc: 0.8171 - mean_squared_error: 0.1547\n",
      "Epoch 14/100\n",
      "984/984 [==============================] - 0s 93us/step - loss: 0.4791 - acc: 0.7947 - mean_squared_error: 0.1536\n",
      "Epoch 15/100\n",
      "984/984 [==============================] - 0s 98us/step - loss: 0.4692 - acc: 0.8222 - mean_squared_error: 0.1484\n",
      "Epoch 16/100\n",
      "984/984 [==============================] - 0s 106us/step - loss: 0.4638 - acc: 0.8211 - mean_squared_error: 0.1466\n",
      "Epoch 17/100\n",
      "984/984 [==============================] - 0s 129us/step - loss: 0.4606 - acc: 0.8171 - mean_squared_error: 0.1453\n",
      "Epoch 18/100\n",
      "984/984 [==============================] - 0s 104us/step - loss: 0.4551 - acc: 0.8232 - mean_squared_error: 0.1428\n",
      "Epoch 19/100\n",
      "984/984 [==============================] - 0s 123us/step - loss: 0.4513 - acc: 0.8191 - mean_squared_error: 0.1423\n",
      "Epoch 20/100\n",
      "984/984 [==============================] - 0s 144us/step - loss: 0.4499 - acc: 0.8242 - mean_squared_error: 0.1410\n",
      "Epoch 21/100\n",
      "984/984 [==============================] - 0s 92us/step - loss: 0.4450 - acc: 0.8181 - mean_squared_error: 0.1396\n",
      "Epoch 22/100\n",
      "984/984 [==============================] - 0s 99us/step - loss: 0.4431 - acc: 0.8232 - mean_squared_error: 0.1387\n",
      "Epoch 23/100\n",
      "984/984 [==============================] - 0s 129us/step - loss: 0.4409 - acc: 0.8242 - mean_squared_error: 0.1378\n",
      "Epoch 24/100\n",
      "984/984 [==============================] - 0s 121us/step - loss: 0.4387 - acc: 0.8242 - mean_squared_error: 0.1372\n",
      "Epoch 25/100\n",
      "984/984 [==============================] - 0s 111us/step - loss: 0.4373 - acc: 0.8232 - mean_squared_error: 0.1366\n",
      "Epoch 26/100\n",
      "984/984 [==============================] - 0s 98us/step - loss: 0.4360 - acc: 0.8252 - mean_squared_error: 0.1361\n",
      "Epoch 27/100\n",
      "984/984 [==============================] - 0s 101us/step - loss: 0.4355 - acc: 0.8272 - mean_squared_error: 0.1357\n",
      "Epoch 28/100\n",
      "984/984 [==============================] - 0s 101us/step - loss: 0.4345 - acc: 0.8262 - mean_squared_error: 0.1354\n",
      "Epoch 29/100\n",
      "984/984 [==============================] - 0s 95us/step - loss: 0.4317 - acc: 0.8272 - mean_squared_error: 0.1345\n",
      "Epoch 30/100\n",
      "984/984 [==============================] - 0s 131us/step - loss: 0.4308 - acc: 0.8262 - mean_squared_error: 0.1343\n",
      "Epoch 31/100\n",
      "984/984 [==============================] - 0s 114us/step - loss: 0.4302 - acc: 0.8262 - mean_squared_error: 0.1339\n",
      "Epoch 32/100\n",
      "984/984 [==============================] - 0s 103us/step - loss: 0.4309 - acc: 0.8222 - mean_squared_error: 0.1342\n",
      "Epoch 33/100\n",
      "984/984 [==============================] - 0s 103us/step - loss: 0.4292 - acc: 0.8272 - mean_squared_error: 0.1330\n",
      "Epoch 34/100\n",
      "984/984 [==============================] - 0s 101us/step - loss: 0.4282 - acc: 0.8283 - mean_squared_error: 0.1332\n",
      "Epoch 35/100\n",
      "984/984 [==============================] - 0s 136us/step - loss: 0.4297 - acc: 0.8242 - mean_squared_error: 0.1336\n",
      "Epoch 36/100\n",
      "984/984 [==============================] - 0s 132us/step - loss: 0.4290 - acc: 0.8262 - mean_squared_error: 0.1333\n",
      "Epoch 37/100\n",
      "984/984 [==============================] - 0s 127us/step - loss: 0.4276 - acc: 0.8262 - mean_squared_error: 0.1322\n",
      "Epoch 38/100\n",
      "984/984 [==============================] - 0s 89us/step - loss: 0.4279 - acc: 0.8293 - mean_squared_error: 0.1326\n",
      "Epoch 39/100\n",
      "984/984 [==============================] - 0s 117us/step - loss: 0.4265 - acc: 0.8272 - mean_squared_error: 0.1324\n",
      "Epoch 40/100\n",
      "984/984 [==============================] - 0s 106us/step - loss: 0.4263 - acc: 0.8283 - mean_squared_error: 0.1319\n",
      "Epoch 41/100\n",
      "984/984 [==============================] - 0s 142us/step - loss: 0.4277 - acc: 0.8283 - mean_squared_error: 0.1328\n",
      "Epoch 42/100\n",
      "984/984 [==============================] - 0s 139us/step - loss: 0.4294 - acc: 0.8232 - mean_squared_error: 0.1337\n",
      "Epoch 43/100\n",
      "984/984 [==============================] - 0s 121us/step - loss: 0.4281 - acc: 0.8303 - mean_squared_error: 0.1329\n",
      "Epoch 44/100\n",
      "984/984 [==============================] - 0s 139us/step - loss: 0.4268 - acc: 0.8303 - mean_squared_error: 0.1321\n",
      "Epoch 45/100\n",
      "984/984 [==============================] - 0s 100us/step - loss: 0.4267 - acc: 0.8283 - mean_squared_error: 0.1319\n",
      "Epoch 46/100\n",
      "984/984 [==============================] - 0s 100us/step - loss: 0.4259 - acc: 0.8232 - mean_squared_error: 0.1322\n",
      "Epoch 47/100\n",
      "984/984 [==============================] - 0s 93us/step - loss: 0.4252 - acc: 0.8283 - mean_squared_error: 0.1316\n",
      "Epoch 48/100\n",
      "984/984 [==============================] - 0s 82us/step - loss: 0.4250 - acc: 0.8262 - mean_squared_error: 0.1316\n",
      "Epoch 49/100\n",
      "984/984 [==============================] - 0s 95us/step - loss: 0.4251 - acc: 0.8303 - mean_squared_error: 0.1314\n",
      "Epoch 50/100\n",
      "984/984 [==============================] - 0s 88us/step - loss: 0.4252 - acc: 0.8262 - mean_squared_error: 0.1312\n",
      "Epoch 51/100\n",
      "984/984 [==============================] - 0s 97us/step - loss: 0.4254 - acc: 0.8283 - mean_squared_error: 0.1315\n",
      "Epoch 52/100\n",
      "984/984 [==============================] - 0s 95us/step - loss: 0.4248 - acc: 0.8293 - mean_squared_error: 0.1313\n",
      "Epoch 53/100\n",
      "984/984 [==============================] - 0s 125us/step - loss: 0.4247 - acc: 0.8252 - mean_squared_error: 0.1313\n",
      "Epoch 54/100\n",
      "984/984 [==============================] - 0s 114us/step - loss: 0.4251 - acc: 0.8283 - mean_squared_error: 0.1311\n",
      "Epoch 55/100\n",
      "984/984 [==============================] - 0s 104us/step - loss: 0.4269 - acc: 0.8303 - mean_squared_error: 0.1318\n",
      "Epoch 56/100\n",
      "984/984 [==============================] - 0s 121us/step - loss: 0.4269 - acc: 0.8262 - mean_squared_error: 0.1323\n",
      "Epoch 57/100\n",
      "984/984 [==============================] - 0s 114us/step - loss: 0.4239 - acc: 0.8313 - mean_squared_error: 0.1307\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "984/984 [==============================] - 0s 109us/step - loss: 0.4252 - acc: 0.8303 - mean_squared_error: 0.1315\n",
      "Epoch 59/100\n",
      "984/984 [==============================] - 0s 96us/step - loss: 0.4247 - acc: 0.8272 - mean_squared_error: 0.1311\n",
      "Epoch 60/100\n",
      "984/984 [==============================] - 0s 98us/step - loss: 0.4255 - acc: 0.8252 - mean_squared_error: 0.1314\n",
      "Epoch 61/100\n",
      "984/984 [==============================] - 0s 90us/step - loss: 0.4262 - acc: 0.8283 - mean_squared_error: 0.1317\n",
      "Epoch 62/100\n",
      "984/984 [==============================] - 0s 92us/step - loss: 0.4245 - acc: 0.8293 - mean_squared_error: 0.1314\n",
      "Epoch 63/100\n",
      "984/984 [==============================] - 0s 132us/step - loss: 0.4241 - acc: 0.8272 - mean_squared_error: 0.1307\n",
      "Epoch 64/100\n",
      "984/984 [==============================] - 0s 100us/step - loss: 0.4277 - acc: 0.8232 - mean_squared_error: 0.1326\n",
      "Epoch 65/100\n",
      "984/984 [==============================] - 0s 95us/step - loss: 0.4245 - acc: 0.8293 - mean_squared_error: 0.1315\n",
      "Epoch 66/100\n",
      "984/984 [==============================] - 0s 95us/step - loss: 0.4227 - acc: 0.8283 - mean_squared_error: 0.1306\n",
      "Epoch 67/100\n",
      "984/984 [==============================] - 0s 93us/step - loss: 0.4232 - acc: 0.8262 - mean_squared_error: 0.1309\n",
      "Epoch 68/100\n",
      "984/984 [==============================] - 0s 95us/step - loss: 0.4233 - acc: 0.8283 - mean_squared_error: 0.1315\n",
      "Epoch 69/100\n",
      "984/984 [==============================] - 0s 119us/step - loss: 0.4220 - acc: 0.8262 - mean_squared_error: 0.1305\n",
      "Epoch 70/100\n",
      "984/984 [==============================] - 0s 103us/step - loss: 0.4217 - acc: 0.8272 - mean_squared_error: 0.1305\n",
      "Epoch 71/100\n",
      "984/984 [==============================] - 0s 89us/step - loss: 0.4223 - acc: 0.8303 - mean_squared_error: 0.1308\n",
      "Epoch 72/100\n",
      "984/984 [==============================] - 0s 86us/step - loss: 0.4209 - acc: 0.8283 - mean_squared_error: 0.1306\n",
      "Epoch 73/100\n",
      "984/984 [==============================] - 0s 94us/step - loss: 0.4219 - acc: 0.8293 - mean_squared_error: 0.1306\n",
      "Epoch 74/100\n",
      "984/984 [==============================] - 0s 88us/step - loss: 0.4207 - acc: 0.8283 - mean_squared_error: 0.1303\n",
      "Epoch 75/100\n",
      "984/984 [==============================] - 0s 134us/step - loss: 0.4204 - acc: 0.8303 - mean_squared_error: 0.1299\n",
      "Epoch 76/100\n",
      "984/984 [==============================] - 0s 98us/step - loss: 0.4204 - acc: 0.8283 - mean_squared_error: 0.1300\n",
      "Epoch 77/100\n",
      "984/984 [==============================] - 0s 100us/step - loss: 0.4202 - acc: 0.8323 - mean_squared_error: 0.1299\n",
      "Epoch 78/100\n",
      "984/984 [==============================] - 0s 93us/step - loss: 0.4197 - acc: 0.8293 - mean_squared_error: 0.1298\n",
      "Epoch 79/100\n",
      "984/984 [==============================] - 0s 92us/step - loss: 0.4212 - acc: 0.8283 - mean_squared_error: 0.1303\n",
      "Epoch 80/100\n",
      "984/984 [==============================] - 0s 98us/step - loss: 0.4226 - acc: 0.8283 - mean_squared_error: 0.1308\n",
      "Epoch 81/100\n",
      "984/984 [==============================] - 0s 89us/step - loss: 0.4200 - acc: 0.8262 - mean_squared_error: 0.1302\n",
      "Epoch 82/100\n",
      "984/984 [==============================] - 0s 102us/step - loss: 0.4199 - acc: 0.8262 - mean_squared_error: 0.1297\n",
      "Epoch 83/100\n",
      "984/984 [==============================] - 0s 89us/step - loss: 0.4191 - acc: 0.8242 - mean_squared_error: 0.1297\n",
      "Epoch 84/100\n",
      "984/984 [==============================] - 0s 108us/step - loss: 0.4186 - acc: 0.8242 - mean_squared_error: 0.1293\n",
      "Epoch 85/100\n",
      "984/984 [==============================] - 0s 116us/step - loss: 0.4188 - acc: 0.8262 - mean_squared_error: 0.1299\n",
      "Epoch 86/100\n",
      "984/984 [==============================] - 0s 117us/step - loss: 0.4211 - acc: 0.8283 - mean_squared_error: 0.1303\n",
      "Epoch 87/100\n",
      "984/984 [==============================] - 0s 135us/step - loss: 0.4194 - acc: 0.8293 - mean_squared_error: 0.1295\n",
      "Epoch 88/100\n",
      "984/984 [==============================] - 0s 114us/step - loss: 0.4184 - acc: 0.8283 - mean_squared_error: 0.1293\n",
      "Epoch 89/100\n",
      "984/984 [==============================] - 0s 91us/step - loss: 0.4196 - acc: 0.8252 - mean_squared_error: 0.1298\n",
      "Epoch 90/100\n",
      "984/984 [==============================] - 0s 101us/step - loss: 0.4204 - acc: 0.8272 - mean_squared_error: 0.1306\n",
      "Epoch 91/100\n",
      "984/984 [==============================] - 0s 103us/step - loss: 0.4185 - acc: 0.8272 - mean_squared_error: 0.1291\n",
      "Epoch 92/100\n",
      "984/984 [==============================] - 0s 115us/step - loss: 0.4202 - acc: 0.8272 - mean_squared_error: 0.1298\n",
      "Epoch 93/100\n",
      "984/984 [==============================] - 0s 119us/step - loss: 0.4195 - acc: 0.8252 - mean_squared_error: 0.1296\n",
      "Epoch 94/100\n",
      "984/984 [==============================] - 0s 113us/step - loss: 0.4201 - acc: 0.8242 - mean_squared_error: 0.1300\n",
      "Epoch 95/100\n",
      "984/984 [==============================] - 0s 109us/step - loss: 0.4181 - acc: 0.8262 - mean_squared_error: 0.1293\n",
      "Epoch 96/100\n",
      "984/984 [==============================] - 0s 97us/step - loss: 0.4183 - acc: 0.8293 - mean_squared_error: 0.1293\n",
      "Epoch 97/100\n",
      "984/984 [==============================] - 0s 98us/step - loss: 0.4191 - acc: 0.8333 - mean_squared_error: 0.1295\n",
      "Epoch 98/100\n",
      "984/984 [==============================] - 0s 99us/step - loss: 0.4175 - acc: 0.8252 - mean_squared_error: 0.1290\n",
      "Epoch 99/100\n",
      "984/984 [==============================] - 0s 112us/step - loss: 0.4187 - acc: 0.8323 - mean_squared_error: 0.1296\n",
      "Epoch 100/100\n",
      "984/984 [==============================] - 0s 116us/step - loss: 0.4176 - acc: 0.8272 - mean_squared_error: 0.1291\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa045121c88>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(10, input_shape=(9,)),\n",
    "    Activation('relu'),\n",
    "#     Dense(20),\n",
    "#     Activation('relu'),\n",
    "    Dense(10),\n",
    "    Activation('relu'),\n",
    "    Dense(1),\n",
    "    Activation('sigmoid'),\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# opt = Adam(lr=0.01)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"acc\", \"mse\"])\n",
    "model.fit(X_train, y_train, epochs=100) #, epochs=100, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "984/984 [==============================] - 0s 215us/step\n",
      "train score: [0.41641413535529037, 0.8252032525171109, 0.12870446162495186]\n",
      "329/329 [==============================] - 0s 61us/step\n",
      "test score: [0.4415990382342353, 0.8389057752571569, 0.1334189323306446]\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_train, y_train)\n",
    "print(\"train score: {}\".format(score))\n",
    "score = model.evaluate(X_test, y_test)\n",
    "print(\"test score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass classification\n",
    "Next we take a look at a classification problem where the result is always exactly one of N classes.  This is called a multi-class problem.\n",
    "(Do not confuse with a _multi-label_ problem, where we can have any number of labels (or none!) positive for a given datum.)\n",
    "\n",
    "In our case we'll try to use the passenger's age, gender and embarkation point to determine the likely class of their ticket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(5, input_shape=(6,)),\n",
    "    Activation('relu'),\n",
    "    Dense(3),\n",
    "    Activation('softmax'),\n",
    "])\n",
    "\n",
    "titanic_class_target = titanic[[\"pclass=1st\",\"pclass=2nd\",\"pclass=3rd\"]]\n",
    "titanic_classless_data = titanic_data.drop([\"pclass=1st\",\"pclass=2nd\",\"pclass=3rd\"], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(titanic_classless_data, titanic_class_target, test_size=0.25, random_state=42)\n",
    "\n",
    "print(X_train.head())\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"acc\", \"mean_squared_error\"])\n",
    "history = model.fit(X_train, y_train, epochs=200)\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['mean_squared_error'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "984/984 [==============================] - 0s 184us/step\n",
      "train score: [0.64367103649348745, 0.70020325154792973, 0.12299748552523977]\n",
      "329/329 [==============================] - 0s 33us/step\n",
      "test score: [0.6473649773735406, 0.71732522814469502, 0.12401590176991054]\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_train, y_train)\n",
    "print(\"train score: {}\".format(score))\n",
    "score = model.evaluate(X_test, y_test)\n",
    "print(\"test score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw softmax (rows should sum to 1):\n",
      " [[ 0.48002222  0.38742185  0.13255596]\n",
      " [ 0.23621719  0.45844388  0.30533892]\n",
      " [ 0.12852886  0.43304601  0.43842512]\n",
      " [ 0.4653298   0.39453498  0.14013521]\n",
      " [ 0.0514151   0.05296337  0.89562154]]\n",
      "\n",
      "Decision boundary at 0.4:\n",
      " [[ True False False]\n",
      " [False  True False]\n",
      " [False  True  True]\n",
      " [ True False False]\n",
      " [False False  True]]\n",
      "\n",
      "Indices of maxima:\n",
      " [0 1 1 0 2]\n"
     ]
    }
   ],
   "source": [
    "y_pred=model.predict(X_test)\n",
    "print(\"Raw softmax (rows should sum to 1):\\n\",y_pred[0:5])\n",
    "y_pred = (y_pred > 0.4)\n",
    "print(\"\\nDecision boundary at 0.4:\\n\",y_pred[0:5])\n",
    "y_args = np.argmax(y_pred, axis=1)\n",
    "print(\"\\nIndices of maxima:\\n\", y_args[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "def measure_performance(X,y,clf, show_accuracy=True, show_classification_report=True, show_confusion_matrix=True):\n",
    "    y_pred=clf.predict(X)\n",
    "    \n",
    "    y = np.argmax(np.array(y), axis=1)\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "    if show_accuracy:\n",
    "        print( \"Accuracy:{0:.3f}\".format(metrics.accuracy_score(y,y_pred)),\"\\n\")\n",
    "\n",
    "    if show_classification_report:\n",
    "        print( \"Classification report\")\n",
    "        print( metrics.classification_report(y,y_pred),\"\\n\")\n",
    "        \n",
    "    if show_confusion_matrix:\n",
    "        print( \"Confusion matrix\")\n",
    "        print( metrics.confusion_matrix(y,y_pred),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.717 \n",
      "\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.66      0.55      0.60        80\n",
      "          1       0.50      0.71      0.59        79\n",
      "          2       0.90      0.80      0.85       170\n",
      "\n",
      "avg / total       0.75      0.72      0.72       329\n",
      " \n",
      "\n",
      "Confusion matrix\n",
      "[[ 44  31   5]\n",
      " [ 13  56  10]\n",
      " [ 10  24 136]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "measure_performance(X_test, y_test, model, show_accuracy=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
