{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get started with interactive Python\n",
    "import turtle\n",
    "from collections import defaultdict\n",
    "\n",
    "wn = turtle.Screen()\n",
    "wn.setup(700,700)\n",
    "wn.bgcolor(\"black\")\n",
    "wn.colormode(1)\n",
    "\n",
    "#create pen\n",
    "class Pen(turtle.Turtle):\n",
    "  def __init__(self):\n",
    "    turtle.Turtle.__init__(self)\n",
    "    self.shape(\"square\")\n",
    "    self.color(\"white\")\n",
    "    self.penup()\n",
    "    self.speed(0)\n",
    "    \n",
    "class Player(turtle.Turtle):\n",
    "  \n",
    "  def __init__(self):\n",
    "    turtle.Turtle.__init__(self)\n",
    "    self.shape(\"square\")\n",
    "    self.color(\"yellow\")\n",
    "    self.penup()\n",
    "    self.speed(0)    \n",
    "    self.wall_R = -0.75\n",
    "    self.move_R = -0.04\n",
    "  \n",
    "  def go_up(self):\n",
    "    move_to_x=player.xcor()\n",
    "    move_to_y=player.ycor() + 24\n",
    "    \n",
    "    if (move_to_x,move_to_y) not in walls:\n",
    "        self.goto(move_to_x, move_to_y)\n",
    "        return self.move_R\n",
    "    else:\n",
    "        return self.wall_R\n",
    "  \n",
    "  def go_down(self):\n",
    "    move_to_x=player.xcor()\n",
    "    move_to_y=player.ycor() - 24\n",
    "    \n",
    "    if (move_to_x,move_to_y) not in walls:\n",
    "        self.goto(move_to_x, move_to_y)  \n",
    "        return self.move_R\n",
    "    else:\n",
    "        return self.wall_R\n",
    "        \n",
    "  def go_right(self):\n",
    "    move_to_x=player.xcor() + 24\n",
    "    move_to_y=player.ycor()\n",
    "    \n",
    "    if (move_to_x,move_to_y) not in walls:\n",
    "        self.goto(move_to_x, move_to_y) \n",
    "        return self.move_R\n",
    "    else:\n",
    "        return self.wall_R\n",
    "    \n",
    "  def go_left(self):\n",
    "    move_to_x=player.xcor() -24\n",
    "    move_to_y=player.ycor()\n",
    "    \n",
    "    if (move_to_x,move_to_y) not in walls:\n",
    "        self.goto(move_to_x, move_to_y) \n",
    "        return self.move_R\n",
    "    else:\n",
    "        return self.wall_R\n",
    "\n",
    "#create Levels list\n",
    "levels = [\"\"]\n",
    "\n",
    "#define first level\n",
    "level_1 = [\n",
    "\"XXXXXXXXXXXXXXXXXXXXXXXXX\",\n",
    "\"X                      XX\",\n",
    "\"X           XXXXXX  XX XX\",\n",
    "\"X  XXXXXXX  XXXXXX  X XXX\",\n",
    "\"X       XXXXXXX        XX\",\n",
    "\"XXXXXX  XX  XXX        XX\",\n",
    "\"XX   X  XX  XXXXXX  XXXXX\",\n",
    "\"XX XXX  XX    XXXX  XXXXX\",\n",
    "\"X  XXXX       XXXX    XXX\",\n",
    "\"X  XXX  XXXXXXXXXXXX   XX\",\n",
    "\"X      X  XXXXXXXXXXX   X\",\n",
    "\"X  XX    XXX     XXXXX  X\",\n",
    "\"X XXXXXXX XX     XXXXX  X\",\n",
    "\"X         XXXXX  XXXXX  X\",\n",
    "\"XXX  XXXXXXXXXX         X\",\n",
    "\"XXX                     X\",\n",
    "\"XXXXXXXXXXXXXXXXXXXXXXXXX\",\n",
    "\"XXXXXXXXXX     X X     PX\",\n",
    "\"X           X           X\",\n",
    "\"X   XX XXXXXX  XXXXX  XXX\",\n",
    "\"XXXX   XXXX             X\",\n",
    "\"X    XX     XXXXXXXXXXX X\",\n",
    "\"X XXX   X               X\",\n",
    "\"X      GX               X\",\n",
    "\"XXXXXXXXXXXXXXXXXXXXXXXXX\"\n",
    "]\n",
    "\n",
    "# level_1=[\n",
    "# \"XXXXXXXXXXXXXXXXXXXXXXXXX\",\n",
    "# \"X                      XX\",\n",
    "# \"X P         XXXXXX  XX XX\",\n",
    "# \"X  XXXXXXX  XXXXXX  X XXX\",\n",
    "# \"X       XXXXXXX        XX\",\n",
    "# \"XXXXXX  XX  XXX        XX\",\n",
    "# \"XX   X  XX  XXXXXX  XXXXX\",\n",
    "# \"XX XXX  XX    XXXX  XXXXX\",\n",
    "# \"X  XXXX       XXXX    XXX\",\n",
    "# \"X  XXX  XXXXXXXXXXXX   XX\",\n",
    "# \"X      X  XXXXXXXXXXX   X\",\n",
    "# \"X  XX    XXX     XXXXX  X\",\n",
    "# \"X XXXXXXX XX     XXXXX  X\",\n",
    "# \"X         XXXXX  XXXXX  X\",\n",
    "# \"XXX  XXXXXXXXXX         X\",\n",
    "# \"XXX                     X\",\n",
    "# \"XXX         XXXXXXXXXXXXX\",\n",
    "# \"XXXXXXXXXX  XXXXXXXXXXXXX\",\n",
    "# \"XXXXXXXXXX              X\",\n",
    "# \"XX  GXXXXX              X\",\n",
    "# \"XX   XXXXXXXXXXXXX  XXXXX\",\n",
    "# \"XX    YXXXXXXXXXXX  XXXXX\",\n",
    "# \"XX          XXXX        X\",\n",
    "# \"XXXX                    X\",\n",
    "# \"XXXXXXXXXXXXXXXXXXXXXXXXX\"\n",
    "# ]\n",
    "\n",
    "\n",
    "#Add maze to mazes list\n",
    "levels.append(level_1)\n",
    "\n",
    "#Create Level Setup Function\n",
    "\n",
    "\n",
    "def setup_maze(level, draw_walls=True, goalstamp=None):\n",
    "    walls = []\n",
    "    playable = []\n",
    "    goal = None\n",
    "    for y in range(len(level)):\n",
    "        for x in range(len(level[y])):\n",
    "          #Get the Character at each x,y coordinate\n",
    "          #NOTE the order of the y and x in the next line\n",
    "            character = level[y][x]\n",
    "    #       Calculate the screen x, y coordinates\n",
    "            screen_x = -288 + (x * 24)\n",
    "            screen_y = 288 - (y * 24)\n",
    "\n",
    "          #Check if it is an X (representing a wall)\n",
    "            if character == \"X\":\n",
    "                if draw_walls:\n",
    "                    pen.color(\"white\")\n",
    "                    pen.goto(screen_x, screen_y)\n",
    "                    pen.stamp()\n",
    "                walls.append((screen_x,screen_y))\n",
    "            else:\n",
    "                playable.append((screen_x, screen_y))\n",
    "\n",
    "            if character == \"P\":\n",
    "                px,py = screen_x, screen_y\n",
    "                player.goto(screen_x, screen_y)\n",
    "\n",
    "            if character == \"G\":\n",
    "                if goalstamp is not None:\n",
    "                    pen.clearstamp(goalstamp)\n",
    "                goal = (screen_x, screen_y)\n",
    "                pen.color(\"green\")\n",
    "                pen.goto(screen_x, screen_y)\n",
    "                goalstamp = pen.stamp()\n",
    "\n",
    "    return walls, goal, goalstamp, playable, px,py\n",
    "        \n",
    "def reset(px,py):\n",
    "    player.goto(px,py)\n",
    "\n",
    "def grid_to_screen(gx,gy):\n",
    "    screen_x = -288 + (gx * 24)\n",
    "    screen_y = 288 - (gy * 24)\n",
    "    return screen_x, screen_y\n",
    "\n",
    "def screen_to_grid(sx,sy):\n",
    "    gx = (sx+288)//24\n",
    "    gy = (288-sy)//24\n",
    "    return gx, gy\n",
    "\n",
    "def grid_to_onehot(gxy, oh=None):\n",
    "    gx = gxy[0]\n",
    "    gy = gxy[1]\n",
    "    if oh is None:\n",
    "        oh = numpy.zeros((24,24))\n",
    "    oh[gx,gy] = 1.0\n",
    "    return oh\n",
    "\n",
    "def grid_to_2hot(gxy, oh=None):\n",
    "    gx = gxy[0]\n",
    "    gy = gxy[1]\n",
    "    h2 = numpy.zeros(48)\n",
    "    h2[gx] = 1.0\n",
    "    h2[24+gy] = 1.0\n",
    "    return h2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Create class instances\n",
    "pen = Pen()\n",
    "pen.speed(0)\n",
    "player=Player()\n",
    "player.speed(0)\n",
    "trail = Pen()\n",
    "trail.color(\"black\")\n",
    "# Walls\n",
    "\n",
    "# print(walls)\n",
    "#Set up the level\n",
    "walls, goal, goalstamp, playable, px,py = setup_maze(levels[1])\n",
    "# print(walls)\n",
    "# wn.tracer(0)\n",
    "\n",
    "\n",
    "#Keyboard Binding\n",
    "# turtle.listen()\n",
    "# turtle.onkey(player.go_left,\"Left\")\n",
    "# turtle.onkey(player.go_right,\"Right\")\n",
    "# turtle.onkey(player.go_up,\"Up\")\n",
    "# turtle.onkey(player.go_down,\"Down\")\n",
    "\n",
    "\n",
    "#Turn off screen upates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0812 23:33:31.105642 140096907028288 deprecation_wrapper.py:119] From /home/rjm49/anaconda3/envs/mlc/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0812 23:33:31.122657 140096907028288 deprecation_wrapper.py:119] From /home/rjm49/anaconda3/envs/mlc/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0812 23:33:31.125725 140096907028288 deprecation_wrapper.py:119] From /home/rjm49/anaconda3/envs/mlc/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0812 23:33:31.183597 140096907028288 deprecation_wrapper.py:119] From /home/rjm49/anaconda3/envs/mlc/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense, PReLU\n",
    "from keras.optimizers import RMSprop, Adam, SGD\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(len(playable), input_shape=(48,), activation=\"relu\"))\n",
    "model.add(Dense(len(playable), activation=\"relu\"))\n",
    "# model.add(Dense(24, activation=\"relu\"))\n",
    "model.add(Dense(4, activation=\"linear\"))\n",
    "model.compile(optimizer=Adam(),loss='mse')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import random\n",
    "from collections import defaultdict, deque\n",
    "#Main Game Loop\n",
    "episode = 0\n",
    "moves = 0\n",
    "draw = True\n",
    "beta = 0.99\n",
    "alpha = 0.8\n",
    "stampcache = {}\n",
    "exp_replay = deque([],100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0812 23:33:31.348083 140096907028288 deprecation_wrapper.py:119] From /home/rjm49/anaconda3/envs/mlc/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting up optimistic starts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0812 23:33:31.437393 140096907028288 deprecation_wrapper.py:119] From /home/rjm49/anaconda3/envs/mlc/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "295/295 [==============================] - 1s 2ms/step - loss: 0.0029\n",
      "Epoch 2/300\n",
      "295/295 [==============================] - 0s 235us/step - loss: 8.4422e-04\n",
      "Epoch 3/300\n",
      "295/295 [==============================] - 0s 179us/step - loss: 4.2433e-04\n",
      "Epoch 4/300\n",
      "295/295 [==============================] - 0s 204us/step - loss: 2.1082e-04\n",
      "Epoch 5/300\n",
      "295/295 [==============================] - 0s 191us/step - loss: 1.2085e-04\n",
      "Epoch 6/300\n",
      "295/295 [==============================] - 0s 178us/step - loss: 7.4059e-05\n",
      "Epoch 7/300\n",
      "295/295 [==============================] - 0s 212us/step - loss: 4.5621e-05\n",
      "Epoch 8/300\n",
      "295/295 [==============================] - 0s 177us/step - loss: 2.5264e-05\n",
      "Epoch 9/300\n",
      "295/295 [==============================] - 0s 169us/step - loss: 1.4716e-05\n",
      "Epoch 10/300\n",
      "295/295 [==============================] - 0s 196us/step - loss: 1.1291e-05\n",
      "Epoch 11/300\n",
      "295/295 [==============================] - 0s 201us/step - loss: 7.0377e-06\n",
      "Epoch 12/300\n",
      "295/295 [==============================] - 0s 179us/step - loss: 4.2280e-06\n",
      "Epoch 13/300\n",
      "295/295 [==============================] - 0s 234us/step - loss: 2.2261e-06\n",
      "Epoch 14/300\n",
      "295/295 [==============================] - 0s 183us/step - loss: 1.3793e-06\n",
      "Epoch 15/300\n",
      "295/295 [==============================] - 0s 187us/step - loss: 9.4787e-07\n",
      "Epoch 16/300\n",
      "295/295 [==============================] - 0s 209us/step - loss: 6.3725e-07\n",
      "Epoch 17/300\n",
      "295/295 [==============================] - 0s 171us/step - loss: 4.2557e-07\n",
      "Epoch 18/300\n",
      "295/295 [==============================] - 0s 184us/step - loss: 3.3109e-07\n",
      "Epoch 19/300\n",
      "295/295 [==============================] - 0s 195us/step - loss: 2.9410e-07\n",
      "Epoch 20/300\n",
      "295/295 [==============================] - 0s 174us/step - loss: 4.3117e-07\n",
      "Epoch 21/300\n",
      "295/295 [==============================] - 0s 231us/step - loss: 2.8135e-07\n",
      "Epoch 22/300\n",
      "295/295 [==============================] - 0s 175us/step - loss: 1.6718e-07\n",
      "Epoch 23/300\n",
      "295/295 [==============================] - 0s 188us/step - loss: 1.3819e-07\n",
      "Epoch 24/300\n",
      "295/295 [==============================] - 0s 228us/step - loss: 9.6066e-08\n",
      "Epoch 25/300\n",
      "295/295 [==============================] - 0s 191us/step - loss: 7.3532e-08\n",
      "Epoch 26/300\n",
      "295/295 [==============================] - 0s 205us/step - loss: 9.0995e-08\n",
      "Epoch 27/300\n",
      "295/295 [==============================] - 0s 187us/step - loss: 5.9779e-08\n",
      "Epoch 28/300\n",
      "295/295 [==============================] - 0s 194us/step - loss: 5.3231e-08\n",
      "Epoch 29/300\n",
      "295/295 [==============================] - 0s 197us/step - loss: 5.3215e-08\n",
      "Epoch 30/300\n",
      "295/295 [==============================] - 0s 170us/step - loss: 4.6171e-08\n",
      "Epoch 31/300\n",
      "295/295 [==============================] - 0s 152us/step - loss: 3.6734e-08\n",
      "Epoch 32/300\n",
      "295/295 [==============================] - 0s 201us/step - loss: 3.8838e-08\n",
      "Epoch 33/300\n",
      "295/295 [==============================] - 0s 185us/step - loss: 2.5711e-08\n",
      "Epoch 34/300\n",
      "295/295 [==============================] - 0s 237us/step - loss: 2.8415e-08\n",
      "Epoch 35/300\n",
      "295/295 [==============================] - 0s 188us/step - loss: 2.3049e-08\n",
      "Epoch 36/300\n",
      "295/295 [==============================] - 0s 180us/step - loss: 2.1581e-08\n",
      "Epoch 37/300\n",
      "295/295 [==============================] - 0s 179us/step - loss: 2.1442e-08\n",
      "Epoch 38/300\n",
      "295/295 [==============================] - 0s 214us/step - loss: 1.6231e-08\n",
      "Epoch 39/300\n",
      "295/295 [==============================] - 0s 170us/step - loss: 1.3735e-08\n",
      "Epoch 40/300\n",
      "295/295 [==============================] - 0s 177us/step - loss: 1.8966e-08\n",
      "Epoch 41/300\n",
      "295/295 [==============================] - 0s 197us/step - loss: 2.5063e-08\n",
      "Epoch 42/300\n",
      "295/295 [==============================] - 0s 189us/step - loss: 2.5976e-08\n",
      "Epoch 43/300\n",
      "295/295 [==============================] - 0s 188us/step - loss: 2.8991e-08\n",
      "Epoch 44/300\n",
      "295/295 [==============================] - 0s 186us/step - loss: 4.8613e-08\n",
      "Epoch 45/300\n",
      "295/295 [==============================] - 0s 167us/step - loss: 5.1053e-08\n",
      "Epoch 46/300\n",
      "295/295 [==============================] - 0s 260us/step - loss: 6.4635e-08\n",
      "Epoch 47/300\n",
      "295/295 [==============================] - 0s 241us/step - loss: 1.0521e-07\n",
      "Epoch 48/300\n",
      "295/295 [==============================] - 0s 192us/step - loss: 1.3030e-07\n",
      "Epoch 49/300\n",
      "295/295 [==============================] - 0s 175us/step - loss: 1.3686e-07\n",
      "Epoch 50/300\n",
      "295/295 [==============================] - 0s 194us/step - loss: 1.8493e-07\n",
      "Epoch 51/300\n",
      "295/295 [==============================] - 0s 194us/step - loss: 3.1477e-07\n",
      "Epoch 52/300\n",
      "295/295 [==============================] - 0s 196us/step - loss: 5.4895e-07\n",
      "Epoch 53/300\n",
      "295/295 [==============================] - 0s 182us/step - loss: 9.6781e-07\n",
      "Epoch 54/300\n",
      "295/295 [==============================] - 0s 153us/step - loss: 1.4800e-06\n",
      "Epoch 55/300\n",
      "295/295 [==============================] - 0s 176us/step - loss: 2.9453e-06\n",
      "Epoch 56/300\n",
      "295/295 [==============================] - 0s 155us/step - loss: 5.0337e-06\n",
      "Epoch 57/300\n",
      "295/295 [==============================] - 0s 202us/step - loss: 7.4680e-06\n",
      "Epoch 58/300\n",
      "295/295 [==============================] - 0s 178us/step - loss: 1.3762e-05\n",
      "Epoch 59/300\n",
      "295/295 [==============================] - 0s 170us/step - loss: 2.2046e-05\n",
      "Epoch 60/300\n",
      "295/295 [==============================] - 0s 175us/step - loss: 2.3793e-05\n",
      "Epoch 61/300\n",
      "295/295 [==============================] - 0s 181us/step - loss: 2.4262e-05\n",
      "Epoch 62/300\n",
      "295/295 [==============================] - 0s 176us/step - loss: 3.5108e-05\n",
      "Epoch 63/300\n",
      "295/295 [==============================] - 0s 181us/step - loss: 4.0851e-05\n",
      "Epoch 64/300\n",
      "295/295 [==============================] - 0s 159us/step - loss: 5.4156e-05\n",
      "Epoch 65/300\n",
      "295/295 [==============================] - 0s 167us/step - loss: 7.0275e-05\n",
      "Epoch 66/300\n",
      "295/295 [==============================] - 0s 190us/step - loss: 6.7884e-05\n",
      "Epoch 67/300\n",
      "295/295 [==============================] - 0s 196us/step - loss: 6.0237e-05\n",
      "Epoch 68/300\n",
      "295/295 [==============================] - 0s 165us/step - loss: 5.7293e-05\n",
      "Epoch 69/300\n",
      "295/295 [==============================] - 0s 215us/step - loss: 4.7366e-05\n",
      "Epoch 70/300\n",
      "295/295 [==============================] - 0s 174us/step - loss: 5.1531e-05\n",
      "Epoch 71/300\n",
      "295/295 [==============================] - 0s 149us/step - loss: 4.5622e-05\n",
      "Epoch 72/300\n",
      "295/295 [==============================] - 0s 190us/step - loss: 3.9192e-05\n",
      "Epoch 73/300\n",
      "295/295 [==============================] - 0s 159us/step - loss: 3.2743e-05\n",
      "Epoch 74/300\n",
      "295/295 [==============================] - 0s 192us/step - loss: 2.3022e-05\n",
      "Epoch 75/300\n",
      "295/295 [==============================] - 0s 181us/step - loss: 1.6242e-05\n",
      "Epoch 76/300\n",
      "295/295 [==============================] - 0s 198us/step - loss: 1.3621e-05\n",
      "Epoch 77/300\n",
      "295/295 [==============================] - 0s 184us/step - loss: 1.0914e-05\n",
      "Epoch 78/300\n",
      "295/295 [==============================] - 0s 193us/step - loss: 9.6122e-06\n",
      "Epoch 79/300\n",
      "295/295 [==============================] - 0s 170us/step - loss: 7.2178e-06\n",
      "Epoch 80/300\n",
      "295/295 [==============================] - 0s 206us/step - loss: 4.5488e-06\n",
      "Epoch 81/300\n",
      "295/295 [==============================] - 0s 174us/step - loss: 3.6238e-06\n",
      "Epoch 82/300\n",
      "295/295 [==============================] - 0s 184us/step - loss: 3.1014e-06\n",
      "Epoch 83/300\n",
      "295/295 [==============================] - 0s 162us/step - loss: 3.3415e-06\n",
      "Epoch 84/300\n",
      "295/295 [==============================] - 0s 201us/step - loss: 5.0074e-06\n",
      "Epoch 85/300\n",
      "295/295 [==============================] - 0s 161us/step - loss: 9.0113e-06\n",
      "Epoch 86/300\n",
      "295/295 [==============================] - 0s 173us/step - loss: 1.2191e-05\n",
      "Epoch 87/300\n",
      "295/295 [==============================] - 0s 141us/step - loss: 7.9797e-06\n",
      "Epoch 88/300\n",
      "295/295 [==============================] - 0s 184us/step - loss: 6.9808e-06\n",
      "Epoch 89/300\n",
      "295/295 [==============================] - 0s 163us/step - loss: 5.2441e-06\n",
      "Epoch 90/300\n",
      "295/295 [==============================] - 0s 183us/step - loss: 3.6622e-06\n",
      "Epoch 91/300\n",
      "295/295 [==============================] - 0s 192us/step - loss: 2.0469e-06\n",
      "Epoch 92/300\n",
      "295/295 [==============================] - 0s 211us/step - loss: 1.9276e-06\n",
      "Epoch 93/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "295/295 [==============================] - 0s 154us/step - loss: 1.5010e-06\n",
      "Epoch 94/300\n",
      "295/295 [==============================] - 0s 183us/step - loss: 9.9914e-07\n",
      "Epoch 95/300\n",
      "295/295 [==============================] - 0s 158us/step - loss: 8.4346e-07\n",
      "Epoch 96/300\n",
      "295/295 [==============================] - 0s 191us/step - loss: 7.4032e-07\n",
      "Epoch 97/300\n",
      "295/295 [==============================] - 0s 180us/step - loss: 6.1328e-07\n",
      "Epoch 98/300\n",
      "295/295 [==============================] - 0s 200us/step - loss: 6.8739e-07\n",
      "Epoch 99/300\n",
      "295/295 [==============================] - 0s 184us/step - loss: 6.9908e-07\n",
      "Epoch 100/300\n",
      "295/295 [==============================] - 0s 181us/step - loss: 6.6376e-07\n",
      "Epoch 101/300\n",
      "295/295 [==============================] - 0s 174us/step - loss: 5.9888e-07\n",
      "Epoch 102/300\n",
      "295/295 [==============================] - 0s 189us/step - loss: 5.7461e-07\n",
      "Epoch 103/300\n",
      "295/295 [==============================] - 0s 188us/step - loss: 6.2306e-07\n",
      "Epoch 104/300\n",
      "295/295 [==============================] - 0s 265us/step - loss: 5.4641e-07\n",
      "Epoch 105/300\n",
      "295/295 [==============================] - 0s 230us/step - loss: 5.7730e-07\n",
      "Epoch 106/300\n",
      "295/295 [==============================] - 0s 175us/step - loss: 5.9494e-07\n",
      "Epoch 107/300\n",
      "295/295 [==============================] - 0s 174us/step - loss: 8.0504e-07\n",
      "Epoch 108/300\n",
      "295/295 [==============================] - 0s 203us/step - loss: 7.7027e-07\n",
      "Epoch 109/300\n",
      "295/295 [==============================] - 0s 185us/step - loss: 8.7657e-07\n",
      "Epoch 110/300\n",
      "295/295 [==============================] - 0s 187us/step - loss: 7.2107e-07\n",
      "Epoch 111/300\n",
      "295/295 [==============================] - 0s 177us/step - loss: 1.0894e-06\n",
      "Epoch 112/300\n",
      "295/295 [==============================] - 0s 174us/step - loss: 1.1984e-06\n",
      "Epoch 113/300\n",
      "295/295 [==============================] - 0s 185us/step - loss: 1.4286e-06\n",
      "Epoch 114/300\n",
      "295/295 [==============================] - 0s 225us/step - loss: 1.6326e-06\n",
      "Epoch 115/300\n",
      "295/295 [==============================] - 0s 188us/step - loss: 2.3819e-06\n",
      "Epoch 116/300\n",
      "295/295 [==============================] - 0s 171us/step - loss: 3.5722e-06\n",
      "Epoch 117/300\n",
      "295/295 [==============================] - 0s 163us/step - loss: 4.8204e-06\n",
      "Epoch 118/300\n",
      "295/295 [==============================] - 0s 159us/step - loss: 4.4947e-06\n",
      "Epoch 119/300\n",
      "295/295 [==============================] - 0s 161us/step - loss: 5.6789e-06\n",
      "Epoch 120/300\n",
      "295/295 [==============================] - 0s 196us/step - loss: 4.8146e-06\n",
      "Epoch 121/300\n",
      "295/295 [==============================] - 0s 171us/step - loss: 4.1419e-06\n",
      "Epoch 122/300\n",
      "295/295 [==============================] - 0s 193us/step - loss: 3.7840e-06\n",
      "Epoch 123/300\n",
      "295/295 [==============================] - 0s 170us/step - loss: 4.3863e-06\n",
      "Epoch 124/300\n",
      "295/295 [==============================] - 0s 176us/step - loss: 5.4163e-06\n",
      "Epoch 125/300\n",
      "295/295 [==============================] - 0s 182us/step - loss: 5.4565e-06\n",
      "Epoch 126/300\n",
      "295/295 [==============================] - 0s 172us/step - loss: 5.6531e-06\n",
      "Epoch 127/300\n",
      "295/295 [==============================] - 0s 221us/step - loss: 6.3941e-06\n",
      "Epoch 128/300\n",
      "295/295 [==============================] - 0s 194us/step - loss: 5.7310e-06\n",
      "Epoch 129/300\n",
      "295/295 [==============================] - 0s 182us/step - loss: 4.5556e-06\n",
      "Epoch 130/300\n",
      "295/295 [==============================] - 0s 186us/step - loss: 4.6249e-06\n",
      "Epoch 131/300\n",
      "295/295 [==============================] - 0s 191us/step - loss: 4.7610e-06\n",
      "Epoch 132/300\n",
      "295/295 [==============================] - 0s 270us/step - loss: 5.6611e-06\n",
      "Epoch 133/300\n",
      "295/295 [==============================] - 0s 183us/step - loss: 5.1383e-06\n",
      "Epoch 134/300\n",
      "295/295 [==============================] - 0s 160us/step - loss: 5.3040e-06\n",
      "Epoch 135/300\n",
      "295/295 [==============================] - 0s 185us/step - loss: 5.6074e-06\n",
      "Epoch 136/300\n",
      "295/295 [==============================] - 0s 187us/step - loss: 6.8441e-06\n",
      "Epoch 137/300\n",
      "295/295 [==============================] - 0s 168us/step - loss: 8.3474e-06\n",
      "Epoch 138/300\n",
      "295/295 [==============================] - 0s 179us/step - loss: 9.3019e-06\n",
      "Epoch 139/300\n",
      "295/295 [==============================] - 0s 166us/step - loss: 1.5253e-05\n",
      "Epoch 140/300\n",
      "295/295 [==============================] - 0s 158us/step - loss: 2.0935e-05\n",
      "Epoch 141/300\n",
      "295/295 [==============================] - 0s 240us/step - loss: 2.0290e-05\n",
      "Epoch 142/300\n",
      "295/295 [==============================] - 0s 209us/step - loss: 1.8024e-05\n",
      "Epoch 143/300\n",
      "295/295 [==============================] - 0s 187us/step - loss: 1.9580e-05\n",
      "Epoch 144/300\n",
      "295/295 [==============================] - 0s 186us/step - loss: 1.9585e-05\n",
      "Epoch 145/300\n",
      "295/295 [==============================] - 0s 181us/step - loss: 1.9066e-05\n",
      "Epoch 146/300\n",
      "295/295 [==============================] - 0s 187us/step - loss: 1.9251e-05\n",
      "Epoch 147/300\n",
      "295/295 [==============================] - 0s 180us/step - loss: 1.3406e-05\n",
      "Epoch 148/300\n",
      "295/295 [==============================] - 0s 202us/step - loss: 1.1203e-05\n",
      "Epoch 149/300\n",
      "295/295 [==============================] - 0s 171us/step - loss: 1.0399e-05\n",
      "Epoch 150/300\n",
      "295/295 [==============================] - 0s 163us/step - loss: 8.5276e-06\n",
      "Epoch 151/300\n",
      "295/295 [==============================] - 0s 166us/step - loss: 7.1049e-06\n",
      "Epoch 152/300\n",
      "295/295 [==============================] - 0s 176us/step - loss: 4.6493e-06\n",
      "Epoch 153/300\n",
      "295/295 [==============================] - 0s 189us/step - loss: 4.4110e-06\n",
      "Epoch 154/300\n",
      "295/295 [==============================] - 0s 178us/step - loss: 3.5821e-06\n",
      "Epoch 155/300\n",
      "295/295 [==============================] - 0s 179us/step - loss: 3.0096e-06\n",
      "Epoch 156/300\n",
      "295/295 [==============================] - 0s 185us/step - loss: 3.8529e-06\n",
      "Epoch 157/300\n",
      "295/295 [==============================] - 0s 183us/step - loss: 3.5046e-06\n",
      "Epoch 158/300\n",
      "295/295 [==============================] - 0s 168us/step - loss: 3.4269e-06\n",
      "Epoch 159/300\n",
      "295/295 [==============================] - 0s 251us/step - loss: 2.9046e-06\n",
      "Epoch 160/300\n",
      "295/295 [==============================] - 0s 171us/step - loss: 5.5755e-06\n",
      "Epoch 161/300\n",
      "295/295 [==============================] - 0s 207us/step - loss: 7.2027e-06\n",
      "Epoch 162/300\n",
      "295/295 [==============================] - 0s 150us/step - loss: 4.8287e-06\n",
      "Epoch 163/300\n",
      "295/295 [==============================] - 0s 152us/step - loss: 6.7508e-06\n",
      "Epoch 164/300\n",
      "295/295 [==============================] - 0s 230us/step - loss: 4.5640e-06\n",
      "Epoch 165/300\n",
      "295/295 [==============================] - 0s 178us/step - loss: 4.1728e-06\n",
      "Epoch 166/300\n",
      "295/295 [==============================] - 0s 151us/step - loss: 3.1150e-06\n",
      "Epoch 167/300\n",
      "295/295 [==============================] - 0s 163us/step - loss: 2.6943e-06\n",
      "Epoch 168/300\n",
      "295/295 [==============================] - 0s 189us/step - loss: 2.2738e-06\n",
      "Epoch 169/300\n",
      "295/295 [==============================] - 0s 173us/step - loss: 1.5381e-06\n",
      "Epoch 170/300\n",
      "295/295 [==============================] - 0s 201us/step - loss: 1.6105e-06\n",
      "Epoch 171/300\n",
      "295/295 [==============================] - 0s 202us/step - loss: 1.4762e-06\n",
      "Epoch 172/300\n",
      "295/295 [==============================] - 0s 200us/step - loss: 1.3610e-06\n",
      "Epoch 173/300\n",
      "295/295 [==============================] - 0s 206us/step - loss: 1.2852e-06\n",
      "Epoch 174/300\n",
      "295/295 [==============================] - 0s 169us/step - loss: 1.5690e-06\n",
      "Epoch 175/300\n",
      "295/295 [==============================] - 0s 190us/step - loss: 1.4660e-06\n",
      "Epoch 176/300\n",
      "295/295 [==============================] - 0s 176us/step - loss: 1.8814e-06\n",
      "Epoch 177/300\n",
      "295/295 [==============================] - 0s 170us/step - loss: 2.4194e-06\n",
      "Epoch 178/300\n",
      "295/295 [==============================] - 0s 181us/step - loss: 2.8205e-06\n",
      "Epoch 179/300\n",
      "295/295 [==============================] - 0s 196us/step - loss: 3.0127e-06\n",
      "Epoch 180/300\n",
      "295/295 [==============================] - 0s 169us/step - loss: 3.0056e-06\n",
      "Epoch 181/300\n",
      "295/295 [==============================] - 0s 182us/step - loss: 3.0413e-06\n",
      "Epoch 182/300\n",
      "295/295 [==============================] - 0s 192us/step - loss: 3.6687e-06\n",
      "Epoch 183/300\n",
      "295/295 [==============================] - 0s 222us/step - loss: 3.7976e-06\n",
      "Epoch 184/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "295/295 [==============================] - 0s 208us/step - loss: 4.3134e-06\n",
      "Epoch 185/300\n",
      "295/295 [==============================] - 0s 209us/step - loss: 3.1772e-06\n",
      "Epoch 186/300\n",
      "295/295 [==============================] - 0s 156us/step - loss: 2.4200e-06\n",
      "Epoch 187/300\n",
      "295/295 [==============================] - 0s 249us/step - loss: 2.6781e-06\n",
      "Epoch 188/300\n",
      "295/295 [==============================] - 0s 200us/step - loss: 3.6997e-06\n",
      "Epoch 189/300\n",
      "295/295 [==============================] - 0s 148us/step - loss: 5.3542e-06\n",
      "Epoch 190/300\n",
      "295/295 [==============================] - 0s 156us/step - loss: 4.6305e-06\n",
      "Epoch 191/300\n",
      "295/295 [==============================] - 0s 176us/step - loss: 3.2567e-06\n",
      "Epoch 192/300\n",
      "295/295 [==============================] - 0s 168us/step - loss: 2.8268e-06\n",
      "Epoch 193/300\n",
      "295/295 [==============================] - 0s 190us/step - loss: 3.0768e-06\n",
      "Epoch 194/300\n",
      "295/295 [==============================] - 0s 171us/step - loss: 4.5213e-06\n",
      "Epoch 195/300\n",
      "295/295 [==============================] - 0s 192us/step - loss: 5.3566e-06\n",
      "Epoch 196/300\n",
      "295/295 [==============================] - 0s 202us/step - loss: 5.3175e-06\n",
      "Epoch 197/300\n",
      "295/295 [==============================] - 0s 175us/step - loss: 4.6597e-06\n",
      "Epoch 198/300\n",
      "295/295 [==============================] - 0s 185us/step - loss: 4.1479e-06\n",
      "Epoch 199/300\n",
      "295/295 [==============================] - 0s 163us/step - loss: 3.5287e-06\n",
      "Epoch 200/300\n",
      "295/295 [==============================] - 0s 167us/step - loss: 3.1162e-06\n",
      "Epoch 201/300\n",
      "295/295 [==============================] - 0s 163us/step - loss: 4.1804e-06\n",
      "Epoch 202/300\n",
      "295/295 [==============================] - 0s 165us/step - loss: 3.7209e-06\n",
      "Epoch 203/300\n",
      "295/295 [==============================] - 0s 163us/step - loss: 4.1160e-06\n",
      "Epoch 204/300\n",
      "295/295 [==============================] - 0s 174us/step - loss: 3.3931e-06\n",
      "Epoch 205/300\n",
      "295/295 [==============================] - 0s 173us/step - loss: 3.2875e-06\n",
      "Epoch 206/300\n",
      "295/295 [==============================] - 0s 165us/step - loss: 5.7547e-06\n",
      "Epoch 207/300\n",
      "295/295 [==============================] - 0s 170us/step - loss: 7.2031e-06\n",
      "Epoch 208/300\n",
      "295/295 [==============================] - 0s 188us/step - loss: 9.1227e-06\n",
      "Epoch 209/300\n",
      "295/295 [==============================] - 0s 183us/step - loss: 8.8131e-06\n",
      "Epoch 210/300\n",
      "295/295 [==============================] - 0s 174us/step - loss: 6.9592e-06\n",
      "Epoch 211/300\n",
      "295/295 [==============================] - 0s 167us/step - loss: 6.5120e-06\n",
      "Epoch 212/300\n",
      "295/295 [==============================] - 0s 180us/step - loss: 6.6660e-06\n",
      "Epoch 213/300\n",
      "295/295 [==============================] - 0s 178us/step - loss: 9.4811e-06\n",
      "Epoch 214/300\n",
      "295/295 [==============================] - 0s 223us/step - loss: 7.8230e-06\n",
      "Epoch 215/300\n",
      "295/295 [==============================] - 0s 197us/step - loss: 6.0237e-06\n",
      "Epoch 216/300\n",
      "295/295 [==============================] - 0s 221us/step - loss: 5.8150e-06\n",
      "Epoch 217/300\n",
      "295/295 [==============================] - 0s 167us/step - loss: 5.7722e-06\n",
      "Epoch 218/300\n",
      "295/295 [==============================] - 0s 167us/step - loss: 6.5403e-06\n",
      "Epoch 219/300\n",
      "295/295 [==============================] - 0s 183us/step - loss: 8.0090e-06\n",
      "Epoch 220/300\n",
      "295/295 [==============================] - 0s 169us/step - loss: 5.7780e-06\n",
      "Epoch 221/300\n",
      "295/295 [==============================] - 0s 176us/step - loss: 4.4815e-06\n",
      "Epoch 222/300\n",
      "295/295 [==============================] - 0s 168us/step - loss: 5.0862e-06\n",
      "Epoch 223/300\n",
      "295/295 [==============================] - 0s 159us/step - loss: 3.5270e-06\n",
      "Epoch 224/300\n",
      "295/295 [==============================] - 0s 185us/step - loss: 3.1790e-06\n",
      "Epoch 225/300\n",
      "295/295 [==============================] - 0s 177us/step - loss: 2.4161e-06\n",
      "Epoch 226/300\n",
      "295/295 [==============================] - 0s 169us/step - loss: 2.4913e-06\n",
      "Epoch 227/300\n",
      "295/295 [==============================] - 0s 170us/step - loss: 2.1813e-06\n",
      "Epoch 228/300\n",
      "295/295 [==============================] - 0s 167us/step - loss: 1.6340e-06\n",
      "Epoch 229/300\n",
      "295/295 [==============================] - 0s 163us/step - loss: 1.6740e-06\n",
      "Epoch 230/300\n",
      "295/295 [==============================] - 0s 198us/step - loss: 1.3260e-06\n",
      "Epoch 231/300\n",
      "295/295 [==============================] - 0s 169us/step - loss: 1.2055e-06\n",
      "Epoch 232/300\n",
      "295/295 [==============================] - 0s 184us/step - loss: 9.3229e-07\n",
      "Epoch 233/300\n",
      "295/295 [==============================] - 0s 179us/step - loss: 9.8814e-07\n",
      "Epoch 234/300\n",
      "295/295 [==============================] - 0s 180us/step - loss: 7.7537e-07\n",
      "Epoch 235/300\n",
      "295/295 [==============================] - 0s 182us/step - loss: 7.3227e-07\n",
      "Epoch 236/300\n",
      "295/295 [==============================] - 0s 212us/step - loss: 2.0139e-06\n",
      "Epoch 237/300\n",
      "295/295 [==============================] - 0s 165us/step - loss: 1.4336e-06\n",
      "Epoch 238/300\n",
      "295/295 [==============================] - 0s 169us/step - loss: 2.6858e-06\n",
      "Epoch 239/300\n",
      "295/295 [==============================] - 0s 196us/step - loss: 2.3876e-06\n",
      "Epoch 240/300\n",
      "295/295 [==============================] - 0s 160us/step - loss: 2.1941e-06\n",
      "Epoch 241/300\n",
      "295/295 [==============================] - 0s 161us/step - loss: 2.0315e-06\n",
      "Epoch 242/300\n",
      "295/295 [==============================] - 0s 166us/step - loss: 2.1871e-06\n",
      "Epoch 243/300\n",
      "295/295 [==============================] - 0s 208us/step - loss: 2.6379e-06\n",
      "Epoch 244/300\n",
      "295/295 [==============================] - 0s 228us/step - loss: 1.9712e-06\n",
      "Epoch 245/300\n",
      "295/295 [==============================] - 0s 191us/step - loss: 2.0683e-06\n",
      "Epoch 246/300\n",
      "295/295 [==============================] - 0s 174us/step - loss: 2.1582e-06\n",
      "Epoch 247/300\n",
      "295/295 [==============================] - 0s 146us/step - loss: 2.0887e-06\n",
      "Epoch 248/300\n",
      "295/295 [==============================] - 0s 167us/step - loss: 1.7842e-06\n",
      "Epoch 249/300\n",
      "295/295 [==============================] - 0s 204us/step - loss: 3.2158e-06\n",
      "Epoch 250/300\n",
      "295/295 [==============================] - 0s 207us/step - loss: 2.1350e-06\n",
      "Epoch 251/300\n",
      "295/295 [==============================] - 0s 199us/step - loss: 1.8829e-06\n",
      "Epoch 252/300\n",
      "295/295 [==============================] - 0s 190us/step - loss: 1.7782e-06\n",
      "Epoch 253/300\n",
      "295/295 [==============================] - 0s 225us/step - loss: 1.6498e-06\n",
      "Epoch 254/300\n",
      "295/295 [==============================] - 0s 181us/step - loss: 1.5409e-06\n",
      "Epoch 255/300\n",
      "295/295 [==============================] - 0s 180us/step - loss: 1.4399e-06\n",
      "Epoch 256/300\n",
      "295/295 [==============================] - 0s 197us/step - loss: 1.4477e-06\n",
      "Epoch 257/300\n",
      "295/295 [==============================] - 0s 168us/step - loss: 2.0928e-06\n",
      "Epoch 258/300\n",
      "295/295 [==============================] - 0s 197us/step - loss: 2.8503e-06\n",
      "Epoch 259/300\n",
      "295/295 [==============================] - 0s 165us/step - loss: 2.4477e-06\n",
      "Epoch 260/300\n",
      "295/295 [==============================] - 0s 221us/step - loss: 2.3169e-06\n",
      "Epoch 261/300\n",
      "295/295 [==============================] - 0s 193us/step - loss: 2.7692e-06\n",
      "Epoch 262/300\n",
      "295/295 [==============================] - 0s 205us/step - loss: 2.9195e-06\n",
      "Epoch 263/300\n",
      "295/295 [==============================] - 0s 188us/step - loss: 2.8347e-06\n",
      "Epoch 264/300\n",
      "295/295 [==============================] - 0s 174us/step - loss: 3.5090e-06\n",
      "Epoch 265/300\n",
      "295/295 [==============================] - 0s 169us/step - loss: 2.6481e-06\n",
      "Epoch 266/300\n",
      "295/295 [==============================] - 0s 171us/step - loss: 2.8221e-06\n",
      "Epoch 267/300\n",
      "295/295 [==============================] - 0s 220us/step - loss: 2.5051e-06\n",
      "Epoch 268/300\n",
      "295/295 [==============================] - 0s 187us/step - loss: 2.4611e-06\n",
      "Epoch 269/300\n",
      "295/295 [==============================] - 0s 179us/step - loss: 2.9795e-06\n",
      "Epoch 270/300\n",
      "295/295 [==============================] - 0s 179us/step - loss: 4.0503e-06\n",
      "Epoch 271/300\n",
      "295/295 [==============================] - 0s 170us/step - loss: 4.1053e-06\n",
      "Epoch 272/300\n",
      "295/295 [==============================] - 0s 217us/step - loss: 6.3869e-06\n",
      "Epoch 273/300\n",
      "295/295 [==============================] - 0s 196us/step - loss: 5.9700e-06\n",
      "Epoch 274/300\n",
      "295/295 [==============================] - 0s 168us/step - loss: 6.4556e-06\n",
      "Epoch 275/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "295/295 [==============================] - 0s 147us/step - loss: 5.7627e-06\n",
      "Epoch 276/300\n",
      "295/295 [==============================] - 0s 223us/step - loss: 6.1920e-06\n",
      "Epoch 277/300\n",
      "295/295 [==============================] - 0s 179us/step - loss: 4.9622e-06\n",
      "Epoch 278/300\n",
      "295/295 [==============================] - 0s 154us/step - loss: 4.8402e-06\n",
      "Epoch 279/300\n",
      "295/295 [==============================] - 0s 187us/step - loss: 7.7730e-06\n",
      "Epoch 280/300\n",
      "295/295 [==============================] - 0s 150us/step - loss: 7.3817e-06\n",
      "Epoch 281/300\n",
      "295/295 [==============================] - 0s 156us/step - loss: 6.9638e-06\n",
      "Epoch 282/300\n",
      "295/295 [==============================] - 0s 165us/step - loss: 8.0862e-06\n",
      "Epoch 283/300\n",
      "295/295 [==============================] - 0s 159us/step - loss: 9.0425e-06\n",
      "Epoch 284/300\n",
      "295/295 [==============================] - 0s 205us/step - loss: 5.3518e-06\n",
      "Epoch 285/300\n",
      "295/295 [==============================] - 0s 167us/step - loss: 4.7218e-06\n",
      "Epoch 286/300\n",
      "295/295 [==============================] - 0s 167us/step - loss: 5.1860e-06\n",
      "Epoch 287/300\n",
      "295/295 [==============================] - 0s 187us/step - loss: 5.3959e-06\n",
      "Epoch 288/300\n",
      "295/295 [==============================] - 0s 197us/step - loss: 6.8759e-06\n",
      "Epoch 289/300\n",
      "295/295 [==============================] - 0s 170us/step - loss: 7.8858e-06\n",
      "Epoch 290/300\n",
      "295/295 [==============================] - 0s 184us/step - loss: 5.5546e-06\n",
      "Epoch 291/300\n",
      "295/295 [==============================] - 0s 189us/step - loss: 3.8763e-06\n",
      "Epoch 292/300\n",
      "295/295 [==============================] - 0s 173us/step - loss: 3.5212e-06\n",
      "Epoch 293/300\n",
      "295/295 [==============================] - 0s 166us/step - loss: 3.2101e-06\n",
      "Epoch 294/300\n",
      "295/295 [==============================] - 0s 160us/step - loss: 2.3162e-06\n",
      "Epoch 295/300\n",
      "295/295 [==============================] - 0s 173us/step - loss: 1.4255e-06\n",
      "Epoch 296/300\n",
      "295/295 [==============================] - 0s 179us/step - loss: 1.3054e-06\n",
      "Epoch 297/300\n",
      "295/295 [==============================] - 0s 158us/step - loss: 7.3382e-07\n",
      "Epoch 298/300\n",
      "295/295 [==============================] - 0s 177us/step - loss: 6.0502e-07\n",
      "Epoch 299/300\n",
      "295/295 [==============================] - 0s 182us/step - loss: 9.6231e-07\n",
      "Epoch 300/300\n",
      "295/295 [==============================] - 0s 203us/step - loss: 6.7246e-07\n",
      "done\n",
      "COLVAL 0.39471566677093506\n",
      "COLVAL 0.41208672523498535\n",
      "COLVAL 0.4034530818462372\n",
      "COLVAL 0.38722410798072815\n",
      "COLVAL 0.3654676079750061\n",
      "COLVAL 0.36437198519706726\n",
      "COLVAL 0.4042668342590332\n",
      "COLVAL 0.375434935092926\n",
      "COLVAL 0.39096805453300476\n",
      "COLVAL 0.357887864112854\n",
      "COLVAL 0.38956695795059204\n",
      "COLVAL 0.39678242802619934\n",
      "COLVAL 0.39141201972961426\n",
      "COLVAL 0.37357744574546814\n",
      "COLVAL 0.36299270391464233\n",
      "COLVAL 0.37769240140914917\n",
      "COLVAL 0.3818861246109009\n",
      "COLVAL 0.3621361255645752\n",
      "COLVAL 0.3932533264160156\n",
      "COLVAL 0.38820597529411316\n",
      "COLVAL 0.38901254534721375\n",
      "COLVAL 0.38927701115608215\n",
      "COLVAL 0.4343077838420868\n",
      "COLVAL 0.41019442677497864\n",
      "COLVAL 0.4139779210090637\n",
      "COLVAL 0.37690892815589905\n",
      "COLVAL 0.4230710566043854\n",
      "COLVAL 0.3891846537590027\n",
      "COLVAL 0.4166550934314728\n",
      "COLVAL 0.4096915125846863\n",
      "COLVAL 0.3810090720653534\n",
      "COLVAL 0.3784946799278259\n",
      "COLVAL 0.3690672516822815\n",
      "COLVAL 0.35339975357055664\n",
      "COLVAL 0.3843400180339813\n",
      "COLVAL 0.3806341588497162\n",
      "COLVAL 0.3715664744377136\n",
      "COLVAL 0.6761593818664551\n",
      "COLVAL 0.4008867144584656\n",
      "COLVAL 0.37031009793281555\n",
      "COLVAL 0.3423328101634979\n",
      "COLVAL 0.36481553316116333\n",
      "COLVAL 0.393201619386673\n",
      "COLVAL 0.42904043197631836\n",
      "COLVAL 0.38534489274024963\n",
      "COLVAL 0.38658955693244934\n",
      "COLVAL 0.40489810705184937\n",
      "COLVAL 0.5067854523658752\n",
      "COLVAL 0.4161555767059326\n",
      "COLVAL 0.42580896615982056\n",
      "COLVAL 0.3745168149471283\n",
      "COLVAL 0.46008557081222534\n",
      "COLVAL 0.41109010577201843\n",
      "COLVAL 0.39262861013412476\n",
      "COLVAL 0.3868339955806732\n",
      "COLVAL 0.4060046076774597\n",
      "COLVAL 0.4495958089828491\n",
      "COLVAL 0.42776864767074585\n",
      "COLVAL 0.4511444866657257\n",
      "COLVAL 0.40480297803878784\n",
      "COLVAL 0.3957798480987549\n",
      "COLVAL 0.4374861717224121\n",
      "COLVAL 0.39738017320632935\n",
      "COLVAL 0.45097318291664124\n",
      "COLVAL 0.43739527463912964\n",
      "COLVAL 0.4012296199798584\n",
      "COLVAL 0.45423051714897156\n",
      "COLVAL 0.38879552483558655\n",
      "COLVAL 0.36045512557029724\n",
      "COLVAL 0.4049797058105469\n",
      "COLVAL 0.37012970447540283\n",
      "COLVAL 0.384645015001297\n",
      "COLVAL 0.3657435476779938\n",
      "COLVAL 0.36746788024902344\n",
      "COLVAL 0.42377668619155884\n",
      "COLVAL 0.3727125823497772\n",
      "COLVAL 0.36182090640068054\n",
      "COLVAL 0.3944653272628784\n",
      "COLVAL 0.40116801857948303\n",
      "COLVAL 0.390577495098114\n",
      "COLVAL 0.4305175542831421\n",
      "COLVAL 0.4218055009841919\n",
      "COLVAL 0.42573124170303345\n",
      "COLVAL 0.38522064685821533\n",
      "COLVAL 0.4104313552379608\n",
      "COLVAL 0.379150927066803\n",
      "COLVAL 0.4114883542060852\n",
      "COLVAL 0.4574713408946991\n",
      "COLVAL 0.403199702501297\n",
      "COLVAL 0.36370959877967834\n",
      "COLVAL 0.3851054608821869\n",
      "COLVAL 0.4002288281917572\n",
      "COLVAL 0.38905438780784607\n",
      "COLVAL 0.4049738347530365\n",
      "COLVAL 0.37603676319122314\n",
      "COLVAL 0.3896106779575348\n",
      "COLVAL 0.3729267120361328\n",
      "COLVAL 0.4114445447921753\n",
      "COLVAL 0.3673934042453766\n",
      "COLVAL 0.38448211550712585\n",
      "COLVAL 0.40949058532714844\n",
      "COLVAL 0.4332042634487152\n",
      "COLVAL 0.3776075839996338\n",
      "COLVAL 0.3747399151325226\n",
      "COLVAL 0.40452858805656433\n",
      "COLVAL 0.4375896453857422\n",
      "COLVAL 0.39658424258232117\n",
      "COLVAL 0.3847630023956299\n",
      "COLVAL 0.3913065493106842\n",
      "COLVAL 0.39464884996414185\n",
      "COLVAL 0.4453611373901367\n",
      "COLVAL 0.39891329407691956\n",
      "COLVAL 0.41298335790634155\n",
      "COLVAL 0.40147629380226135\n",
      "COLVAL 0.39730989933013916\n",
      "COLVAL 0.3966662585735321\n",
      "COLVAL 0.36633744835853577\n",
      "COLVAL 0.378913938999176\n",
      "COLVAL 0.3874790072441101\n",
      "COLVAL 0.49199238419532776\n",
      "COLVAL 0.40835997462272644\n",
      "COLVAL 1.0\n",
      "COLVAL 0.40954679250717163\n",
      "COLVAL 0.40853607654571533\n",
      "COLVAL 0.48435354232788086\n",
      "COLVAL 0.5569881200790405\n",
      "COLVAL 0.4199388027191162\n",
      "COLVAL 0.3971658945083618\n",
      "COLVAL 0.5970978140830994\n",
      "COLVAL 0.40162158012390137\n",
      "COLVAL 0.4310687184333801\n",
      "COLVAL 0.4948040246963501\n",
      "COLVAL 0.4319697618484497\n",
      "COLVAL 0.3878495693206787\n",
      "COLVAL 0.4121612012386322\n",
      "COLVAL 0.3972284495830536\n",
      "COLVAL 0.403653085231781\n",
      "COLVAL 0.3778937757015228\n",
      "COLVAL 0.407114714384079\n",
      "COLVAL 0.38883641362190247\n",
      "COLVAL 0.40009498596191406\n",
      "COLVAL 0.45103830099105835\n",
      "COLVAL 0.4058648347854614\n",
      "COLVAL 0.40672987699508667\n",
      "COLVAL 0.4805077910423279\n",
      "COLVAL 0.3547285497188568\n",
      "COLVAL 0.41881686449050903\n",
      "COLVAL 0.42088383436203003\n",
      "COLVAL 0.4313277304172516\n",
      "COLVAL 0.40076425671577454\n",
      "COLVAL 0.45965075492858887\n",
      "COLVAL 0.4515054523944855\n",
      "COLVAL 0.39442843198776245\n",
      "COLVAL 0.3975021541118622\n",
      "COLVAL 0.41330769658088684\n",
      "COLVAL 0.4459259510040283\n",
      "COLVAL 0.38613614439964294\n",
      "COLVAL 0.5964961051940918\n",
      "COLVAL 0.40345290303230286\n",
      "COLVAL 0.39860185980796814\n",
      "COLVAL 0.3862164318561554\n",
      "COLVAL 0.4108346402645111\n",
      "COLVAL 0.39413097500801086\n",
      "COLVAL 0.422678142786026\n",
      "COLVAL 0.413277268409729\n",
      "COLVAL 0.4014580249786377\n",
      "COLVAL 0.3683536648750305\n",
      "COLVAL 0.38086244463920593\n",
      "COLVAL 0.41394731402397156\n",
      "COLVAL 0.41954824328422546\n",
      "COLVAL 0.39309659600257874\n",
      "COLVAL 0.3719431161880493\n",
      "COLVAL 0.38204139471054077\n",
      "COLVAL 0.3778573274612427\n",
      "COLVAL 0.384054571390152\n",
      "COLVAL 0.3731268346309662\n",
      "COLVAL 0.37870845198631287\n",
      "COLVAL 0.3790991008281708\n",
      "COLVAL 0.407077819108963\n",
      "COLVAL 0.38609641790390015\n",
      "COLVAL 0.3975376486778259\n",
      "COLVAL 0.3906550705432892\n",
      "COLVAL 0.3588888943195343\n",
      "COLVAL 0.37990516424179077\n",
      "COLVAL 0.3840871751308441\n",
      "COLVAL 0.3843386173248291\n",
      "COLVAL 0.36344924569129944\n",
      "COLVAL 0.3880845010280609\n",
      "COLVAL 0.4144027829170227\n",
      "COLVAL 0.411258727312088\n",
      "COLVAL 0.3773999810218811\n",
      "COLVAL 0.4653570055961609\n",
      "COLVAL 0.4005183279514313\n",
      "COLVAL 0.5785485506057739\n",
      "COLVAL 0.3796297311782837\n",
      "COLVAL 0.4177134335041046\n",
      "COLVAL 0.4098713994026184\n",
      "COLVAL 0.39288580417633057\n",
      "COLVAL 0.39125338196754456\n",
      "COLVAL 0.4237444996833801\n",
      "COLVAL 0.44221338629722595\n",
      "COLVAL 0.4060942530632019\n",
      "COLVAL 0.41572844982147217\n",
      "COLVAL 0.43398305773735046\n",
      "COLVAL 0.4105279743671417\n",
      "COLVAL 0.4288750886917114\n",
      "COLVAL 0.3625318706035614\n",
      "COLVAL 0.39509958028793335\n",
      "COLVAL 0.3916814923286438\n",
      "COLVAL 0.38258787989616394\n",
      "COLVAL 0.391548216342926\n",
      "COLVAL 0.41730356216430664\n",
      "COLVAL 0.4441543519496918\n",
      "COLVAL 0.40509840846061707\n",
      "COLVAL 0.40816372632980347\n",
      "COLVAL 0.39152857661247253\n",
      "COLVAL 0.40043824911117554\n",
      "COLVAL 0.43551862239837646\n",
      "COLVAL 0.46890828013420105\n",
      "COLVAL 0.4065723121166229\n",
      "COLVAL 0.45812225341796875\n",
      "COLVAL 0.41344162821769714\n",
      "COLVAL 0.392731636762619\n",
      "COLVAL 0.3902829885482788\n",
      "COLVAL 0.38128527998924255\n",
      "COLVAL 0.3751959800720215\n",
      "COLVAL 0.40350839495658875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLVAL 0.4167972803115845\n",
      "COLVAL 0.43821561336517334\n",
      "COLVAL 0.5319951176643372\n",
      "COLVAL 0.3784186840057373\n",
      "COLVAL 0.37427565455436707\n",
      "COLVAL 0.4100028872489929\n",
      "COLVAL 0.3985922038555145\n",
      "COLVAL 0.3749508261680603\n",
      "COLVAL 0.34369975328445435\n",
      "COLVAL 0.46089982986450195\n",
      "COLVAL 0.39107564091682434\n",
      "COLVAL 0.37805303931236267\n",
      "COLVAL 0.4071698486804962\n",
      "COLVAL 0.3810262978076935\n",
      "COLVAL 0.3966534435749054\n",
      "COLVAL 0.3863784074783325\n",
      "COLVAL 0.4201788604259491\n",
      "COLVAL 0.4155091643333435\n",
      "COLVAL 0.4305441677570343\n",
      "COLVAL 0.6455838680267334\n",
      "COLVAL 0.5018160343170166\n",
      "COLVAL 0.4328851103782654\n",
      "COLVAL 0.4164053797721863\n",
      "COLVAL 0.40436145663261414\n",
      "COLVAL 0.39588162302970886\n",
      "COLVAL 0.390201598405838\n",
      "COLVAL 0.43215689063072205\n",
      "COLVAL 0.3995087742805481\n",
      "COLVAL 0.46853169798851013\n",
      "COLVAL 0.38149067759513855\n",
      "COLVAL 0.41131502389907837\n",
      "COLVAL 0.41026872396469116\n",
      "COLVAL 0.3691614866256714\n",
      "COLVAL 0.3891006410121918\n",
      "COLVAL 0.3916752338409424\n",
      "COLVAL 0.4025384485721588\n",
      "COLVAL 0.3744736313819885\n",
      "COLVAL 0.4164274334907532\n",
      "COLVAL 0.4178915321826935\n",
      "COLVAL 0.39165857434272766\n",
      "COLVAL 0.3883582055568695\n",
      "COLVAL 0.40304699540138245\n",
      "COLVAL 0.36720961332321167\n",
      "COLVAL 0.40965208411216736\n",
      "COLVAL 0.3797588050365448\n",
      "COLVAL 0.400855153799057\n",
      "COLVAL 0.35966336727142334\n",
      "COLVAL 0.3645973205566406\n",
      "COLVAL 0.4255060851573944\n",
      "COLVAL 0.4035796523094177\n",
      "COLVAL 0.43342113494873047\n",
      "COLVAL 0.4446912109851837\n",
      "COLVAL 0.37775298953056335\n",
      "COLVAL 0.3819458484649658\n",
      "COLVAL 0.4050741195678711\n",
      "COLVAL 0.3681555688381195\n",
      "COLVAL 0.3788028061389923\n",
      "COLVAL 0.3842851519584656\n",
      "COLVAL 0.3545739948749542\n",
      "COLVAL 0.4041318893432617\n",
      "COLVAL 0.39473479986190796\n",
      "COLVAL 0.39402562379837036\n",
      "COLVAL 0.4024297297000885\n",
      "COLVAL 0.3516780436038971\n",
      "COLVAL 0.39553824067115784\n",
      "COLVAL 0.39923200011253357\n",
      "COLVAL 0.407287061214447\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "mv_list = ['L','R','U','D']\n",
    "last_mv = None\n",
    "\n",
    "\n",
    "ohs = []\n",
    "print(\"setting up optimistic starts\")\n",
    "for (sx,sy) in playable:\n",
    "    gx,gy = screen_to_grid(sx,sy)\n",
    "    oh = grid_to_2hot((gx,gy))\n",
    "    ohs.append(oh)\n",
    "init_scores=numpy.array([[0,0,0,0] for el in ohs])\n",
    "ohs = numpy.array(ohs).reshape(-1,48)\n",
    "model.fit(ohs, init_scores, epochs=300, verbose=1, shuffle=True)\n",
    "print(\"done\")\n",
    "\n",
    "\n",
    "max_R = -math.inf\n",
    "min_R = math.inf\n",
    "for (sx,sy) in playable:\n",
    "    gx,gy = screen_to_grid(sx,sy)\n",
    "    oh = grid_to_2hot((gx,gy))\n",
    "    poss_mvs = model.predict(oh.reshape(1,48))[0]\n",
    "    if max(poss_mvs) > max_R:\n",
    "        max_R = max(poss_mvs)\n",
    "    if min(poss_mvs) < min_R:\n",
    "        min_R = min(poss_mvs)\n",
    "        \n",
    "for (sx,sy) in playable:\n",
    "    if (sx,sy)==goal:\n",
    "        continue\n",
    "    gx,gy = screen_to_grid(sx,sy)\n",
    "    oh = grid_to_2hot((gx,gy))\n",
    "    poss_mvs = model.predict(oh.reshape(1,48))[0]\n",
    "    colval = float((numpy.max(poss_mvs) -min_R)/(max_R-min_R)) if (max_R-min_R) else 0.5\n",
    "    print(\"COLVAL\", colval)\n",
    "    trail.fillcolor(colval , 0,0 )\n",
    "    trail.goto(sx,sy)\n",
    "    stampid = trail.stamp()\n",
    "    stampcache[(sx,sy)] = stampid\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# init_scores=numpy.array([[0,0,0,0] for el in playable])\n",
    "# init_locations = numpy.array(playable)\n",
    "# model.fit(init_locations, init_scores, epochs=1000, verbose=1)\n",
    "# init_pred = model.predict(init_locations)\n",
    "\n",
    "# input(\"hit return\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264 -120\n",
      "mazes_run=1, moves_this_maze=477, wins=1 | winrate=0.0020964360587002098\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping( monitor=\"loss\", patience=5, restore_best_weights=True)\n",
    "wn.tracer(0)\n",
    "episode=1\n",
    "\n",
    "win = False\n",
    "n_wins = 0\n",
    "lose = False\n",
    "moves = 0\n",
    "global_moves = 0\n",
    "seen = set()\n",
    "print(px,py)\n",
    "player.goto(px,py)\n",
    "x,y=px,py\n",
    "while True:\n",
    "    min_Q = math.inf\n",
    "    max_Q = -math.inf\n",
    "    if global_moves % 25 == 0: #Update the lava grid every 25 moves\n",
    "        for (sx,sy) in playable:            \n",
    "            gx,gy = screen_to_grid(sx,sy)\n",
    "            oh_xy = grid_to_2hot((gx,gy))    \n",
    "            poss_mvs = model.predict(oh_xy.reshape(1,-1))[0]\n",
    "            if max(poss_mvs) > max_Q:\n",
    "                max_Q = max(poss_mvs)\n",
    "            if min(poss_mvs) < min_Q:\n",
    "                min_Q = min(poss_mvs)\n",
    "        for (sx,sy) in playable:            \n",
    "            if (sx,sy)==goal:\n",
    "                continue\n",
    "            if (sx,sy)==(x,y):\n",
    "                continue\n",
    "            gx,gy = screen_to_grid(sx,sy)\n",
    "            oh_xy = grid_to_2hot((gx,gy))    \n",
    "            poss_mvs = model.predict(oh_xy.reshape(1,-1))[0]\n",
    "            colval = float((numpy.max(poss_mvs)-min_Q)/(max_Q-min_Q)) if (max_Q-min_Q) else 0.5\n",
    "    #                 print(\"minR, maxR, COLVAL\", min_Q, max_Q, colval)\n",
    "            trail.fillcolor(colval , 0,0 )\n",
    "            trail.goto(sx,sy)\n",
    "            if (sx,sy) in stampcache:\n",
    "                trail.clearstamp( stampcache[(sx,sy)] )\n",
    "            stampid = trail.stamp()\n",
    "            stampcache[(sx,sy)] = stampid    \n",
    "    \n",
    "    wn.update()\n",
    "    x = (player.xcor())\n",
    "    y = (player.ycor())\n",
    "    s = grid_to_2hot(screen_to_grid(x,y))\n",
    "\n",
    "    R_sa = 0\n",
    "    poss_mvs = model.predict( numpy.array(s).reshape(1,-1) )[0]\n",
    "    if random.random() < 0.1:\n",
    "        mv = random.choice(mv_list)\n",
    "        mv_ix = mv_list.index(mv)\n",
    "    else:\n",
    "        mv_ix = numpy.argmax(poss_mvs)\n",
    "        mv = mv_list[mv_ix]\n",
    "\n",
    "    if mv == \"L\":\n",
    "        R_sa= player.go_left()\n",
    "    elif mv == \"R\":\n",
    "        R_sa= player.go_right()\n",
    "    elif mv == \"U\":\n",
    "        R_sa= player.go_up()\n",
    "    elif mv == \"D\":\n",
    "        R_sa= player.go_down()\n",
    "\n",
    "    xn = (player.xcor())\n",
    "    yn = (player.ycor())\n",
    "    \n",
    "    if (xn,yn) in seen:\n",
    "        R_sa = -0.25\n",
    "    else:\n",
    "        seen.add((xn,yn))\n",
    "\n",
    "#     sn = grid_to_2hot(screen_to_grid(x,y))\n",
    "    if (xn,yn) == goal:\n",
    "        R_sa = 1.0\n",
    "#         Q_next = 0 #there is no \"next square\"\n",
    "        win=True   #YEFF!\n",
    "#     else:\n",
    "#         Q_next = max(model.predict( numpy.array(sn).reshape(1,-1) )[0])\n",
    "#     poss_mvs[mv_ix] = R_sa + Q_next    \n",
    "#     model.fit( numpy.array(sn).reshape(1,48), numpy.array(poss_mvs).reshape(1,4), epochs=1000, verbose=0, callbacks=[es])\n",
    "\n",
    "    moves+=1\n",
    "    if moves>=500:\n",
    "        lose=True #FAIL!\n",
    "\n",
    "    new_exp = [x,y, mv_ix, R_sa, xn,yn]\n",
    "    exp_replay.append(new_exp)\n",
    "\n",
    "    if moves % 10:\n",
    "        cxs = numpy.random.choice(numpy.arange(len(exp_replay)), size= min(50,len(exp_replay)))\n",
    "        x_ohxy_list = []\n",
    "        x_poss_move_list = []\n",
    "#         print(\"exp replay with\", len(cxs),\"samples.\")\n",
    "\n",
    "        for cx in cxs:\n",
    "            x,y, mv_ix, mvR, xn,yn = exp_replay[cx]   \n",
    "            oh_xy = grid_to_2hot(screen_to_grid(x,y))\n",
    "            oh_xyn = grid_to_2hot(screen_to_grid(xn,yn))\n",
    "            poss_mvs = model.predict(oh_xy.reshape(1,-1))[0]\n",
    "            if (xn,yn)==goal:\n",
    "                poss_mvs[mv_ix] = mvR\n",
    "            else:\n",
    "                Q_next = max(model.predict(oh_xyn.reshape(1,-1))[0])\n",
    "                poss_mvs[mv_ix] =  mvR + Q_next\n",
    "            x_ohxy_list.append(oh_xy)\n",
    "            x_poss_move_list.append(poss_mvs)\n",
    "    #     if len(x_poss_move_list) > 10:\n",
    "        model.fit( numpy.array(x_ohxy_list).reshape(-1,48), numpy.array(x_poss_move_list).reshape(-1,4), epochs=1000, verbose=0, shuffle=True, callbacks=[es])\n",
    "\n",
    "    if win or lose:\n",
    "        if win:\n",
    "            n_wins+=1\n",
    "        print(\"mazes_run={}, moves_this_maze={}, wins={} | winrate={}\".format(episode, moves, n_wins, n_wins/moves))\n",
    "        player.goto(px,py)\n",
    "        win=False\n",
    "        lose=False\n",
    "        moves=0\n",
    "        episode+=1\n",
    "        seen=set()\n",
    "\n",
    "\n",
    "# while True:\n",
    "# \n",
    "#     moves_this_episode = []\n",
    "  # Update Screen\n",
    "#     if draw:# and (moves % 10==0):\n",
    "#         if(moves % 1==0):\n",
    "#             min_Q = math.inf\n",
    "#             max_Q = -math.inf\n",
    "#             for (sx,sy) in playable:            \n",
    "#                 gx,gy = screen_to_grid(sx,sy)\n",
    "#                 oh_xy = grid_to_onehot((gx,gy))    \n",
    "#                 poss_mvs = model.predict(oh_xy.reshape(1,-1))[0]\n",
    "#                 if max(poss_mvs) > max_Q:\n",
    "#                     max_Q = max(poss_mvs)\n",
    "#                 if min(poss_mvs) < min_Q:\n",
    "#                     min_Q = min(poss_mvs)\n",
    "#             for (sx,sy) in playable:            \n",
    "#                 if (sx,sy)==goal:\n",
    "#                     continue\n",
    "#                 if (sx,sy)==(x,y):\n",
    "#                     continue\n",
    "#                 gx,gy = screen_to_grid(sx,sy)\n",
    "#                 oh_xy = grid_to_onehot((gx,gy))    \n",
    "#                 poss_mvs = model.predict(oh_xy.reshape(1,-1))[0]\n",
    "#                 colval = float((numpy.max(poss_mvs)-min_Q)/(max_Q-min_Q)) if (max_Q-min_Q) else 0.5\n",
    "# #                 print(\"minR, maxR, COLVAL\", min_Q, max_Q, colval)\n",
    "#                 trail.fillcolor(colval , 0,0 )\n",
    "#                 trail.goto(sx,sy)\n",
    "#                 if (sx,sy) in stampcache:\n",
    "#                     trail.clearstamp( stampcache[(sx,sy)] )\n",
    "#                 stampid = trail.stamp()\n",
    "#                 stampcache[(sx,sy)] = stampid\n",
    "#         wn.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
